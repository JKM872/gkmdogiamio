"""
Livesport H2H scraper - Multi-Sport Edition
-------------------------------------------
Cel: dla danego dnia zapisaƒá do pliku CSV wydarzenia (mecze), w kt√≥rych GOSPODARZE pokonali przeciwnik√≥w co najmniej 2 razy w ostatnich 5 bezpo≈õrednich spotkaniach (H2H).

Wspierane sporty:
- Pi≈Çka no≈ºna (football/soccer)
- Koszyk√≥wka (basketball)
- Siatk√≥wka (volleyball)
- Pi≈Çka rƒôczna (handball)
- Rugby
- Hokej (hockey/ice-hockey)

Uwagi / za≈Ço≈ºenia:
- Zak≈Çadam, ≈ºe "ostatnie 5" oznacza 5 ostatnich bezpo≈õrednich spotka≈Ñ miƒôdzy obiema dru≈ºynami (H2H na stronie meczu).
- Skrypt pracuje w trzech trybach:
    * --urls  : przetwarza listƒô adres√≥w URL mecz√≥w (plik tekstowy z jednƒÖ liniƒÖ = jeden URL)
    * --auto  : pr√≥buje zebraƒá listƒô link√≥w do mecz√≥w z og√≥lnej strony dla danego dnia
    * --sport : automatycznie zbiera linki dla konkretnych sport√≥w
- Strona Livesport jest mocno zale≈ºna od JS ‚Äî skrypt u≈ºywa Selenium (Chrome/Chromedriver).
- Przestrzegaj robots.txt i Terms of Use. Skrypt ma op√≥≈∫nienia (sleep) i limit pr√≥b, ale u≈ºywanie go na du≈ºej skali wymaga uzyskania zgody od w≈Ça≈õciciela serwisu.

Wymagania:
- Python 3.9+
- pip install selenium beautifulsoup4 pandas webdriver-manager
- Chrome i dopasowany chromedriver (webdriver-manager u≈Çatwia instalacjƒô)

Uruchomienie (przyk≈Çady):
python livesport_h2h_scraper.py --mode urls --date 2025-10-05 --input match_urls.txt --headless
python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football basketball --headless
python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football --leagues ekstraklasa premier-league --headless

Plik wynikowy: outputs/livesport_h2h_YYYY-MM-DD.csv (lub z sufixem sportu)

"""

import argparse
import time
import os
import csv
import re
import json
import gc  # Garbage collector dla zarzƒÖdzania pamiƒôciƒÖ
from datetime import datetime
from typing import List, Dict, Optional

import pandas as pd
from bs4 import BeautifulSoup

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager

# Import w≈Çasnych modu≈Ç√≥w
import over_under_analyzer


# ----------------------
# Helper / scraper code
# ----------------------

# Globalna zmienna kontrolujƒÖca poziom szczeg√≥≈Çowo≈õci log√≥w
VERBOSE = False  # Domy≈õlnie wy≈ÇƒÖczone, w≈ÇƒÖczane przez --verbose

# Mapowanie sport√≥w na URLe Livesport
SPORT_URLS = {
    'football': 'https://www.livesport.com/pl/pilka-nozna/',
    'soccer': 'https://www.livesport.com/pl/pilka-nozna/',
    'basketball': 'https://www.livesport.com/pl/koszykowka/',
    'volleyball': 'https://www.livesport.com/pl/siatkowka/',
    'handball': 'https://www.livesport.com/pl/pilka-reczna/',
    'rugby': 'https://www.livesport.com/pl/rugby/',
    'hockey': 'https://www.livesport.com/pl/hokej/',
    'ice-hockey': 'https://www.livesport.com/pl/hokej/',
    'tennis': 'https://www.livesport.com/pl/tenis/',
}

# Sporty indywidualne (inna logika kwalifikacji)
INDIVIDUAL_SPORTS = ['tennis']

# Popularne ligi dla ka≈ºdego sportu (mapowanie slug -> nazwa)
POPULAR_LEAGUES = {
    'football': {
        'ekstraklasa': 'Ekstraklasa',
        'premier-league': 'Premier League',
        'la-liga': 'LaLiga',
        'bundesliga': 'Bundesliga',
        'serie-a': 'Serie A',
        'ligue-1': 'Ligue 1',
        'champions-league': 'Liga Mistrz√≥w',
        'europa-league': 'Liga Europy',
    },
    'basketball': {
        'nba': 'NBA',
        'euroleague': 'Euroliga',
        'energa-basket-liga': 'Energa Basket Liga',
        'pbl': 'Polska Liga Koszyk√≥wki',
    },
    'volleyball': {
        'plusliga': 'PlusLiga',
        'tauron-liga': 'Tauron Liga',
    },
    'handball': {
        'pgnig-superliga': 'PGNiG Superliga',
    },
    'rugby': {
        'premiership': 'Premiership',
        'top-14': 'Top 14',
    },
    'hockey': {
        'nhl': 'NHL',
        'khl': 'KHL',
    },
}

H2H_TAB_TEXT_OPTIONS = ["H2H", "Head-to-Head", "Bezpo≈õrednie", "Bezpo≈õrednie spotkania", "H2H"]


def start_driver(headless: bool = True) -> webdriver.Chrome:
    chrome_options = Options()
    if headless:
        chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument('--window-size=1920,1080')
    # human-like user-agent (you may rotate)
    chrome_options.add_argument(
        "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver


def click_h2h_tab(driver: webdriver.Chrome) -> None:
    """Spr√≥buj kliknƒÖƒá zak≈Çadkƒô H2H - sprawdzamy kilka wariant√≥w tekstowych i atrybut√≥w."""
    for text in H2H_TAB_TEXT_OPTIONS:
        try:
            # XPath contains text
            el = driver.find_element(By.XPATH, f"//a[contains(translate(normalize-space(.), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{text.lower()}')]")
            el.click()
            time.sleep(0.8)
            return
        except Exception:
            pass

    # fallback: look for element with data-tab or href containing 'h2h'
    try:
        el = driver.find_element(By.XPATH, "//a[contains(@href, 'h2h') or contains(@data-tab, 'h2h')]")
        el.click()
        time.sleep(0.8)
        return
    except Exception:
        pass

    # if nothing works, do nothing and hope content is already present


def parse_h2h_from_soup(soup: BeautifulSoup, home_team: str, debug_url: str = None) -> List[Dict]:
    """Parsuje sekcjƒô H2H i zwraca listƒô ostatnich spotka≈Ñ (do 5).
    Zwracany format: [{'date':..., 'home':..., 'away':..., 'score': 'x - y', 'winner': 'home'/'away'/'draw'}]
    """
    results = []

    # METODA 1: Szukaj sekcji H2H
    h2h_sections = soup.find_all('div', class_='h2h__section')
    
    if not h2h_sections:
        h2h_sections = soup.find_all('div', class_=re.compile(r'h2h'))
    
    if not h2h_sections:
        # METODA 2: Szukaj bezpo≈õrednio wierszy H2H
        all_h2h_rows = soup.select('a.h2h__row, div.h2h__row, [class*="h2h__row"]')
        if all_h2h_rows:
            return _parse_h2h_rows(all_h2h_rows[:5], debug_url)
    
    # DEBUG: Zapisz HTML gdy brak H2H
    if not h2h_sections and debug_url:
        try:
            debug_file = 'outputs/debug_no_h2h.html'
            os.makedirs('outputs', exist_ok=True)
            with open(debug_file, 'w', encoding='utf-8') as f:
                f.write(f"<!-- DEBUG: Brak sekcji H2H dla URL: {debug_url} -->\n")
                f.write(str(soup.prettify()))
        except:
            pass
    
    # Szukaj sekcji "Pojedynki bezpo≈õrednie"
    pojedynki_section = None
    for section in h2h_sections:
        text = section.get_text(" ", strip=True)
        if 'pojedynki' in text.lower() or 'bezpo≈õrednie' in text.lower() or 'head' in text.lower():
            pojedynki_section = section
            break
    
    if not pojedynki_section and h2h_sections:
        pojedynki_section = h2h_sections[0]
    
    if not pojedynki_section:
        return results
    
    # Znajd≈∫ wiersze z meczami - pr√≥buj r√≥≈ºnych selektor√≥w
    match_rows = pojedynki_section.select('a.h2h__row')
    if not match_rows:
        match_rows = pojedynki_section.select('div.h2h__row')
    if not match_rows:
        match_rows = pojedynki_section.select('[class*="h2h__row"]')
    if not match_rows:
        match_rows = pojedynki_section.select('a, div[class*="row"]')
    
    return _parse_h2h_rows(match_rows[:5], debug_url)


def _parse_h2h_rows(match_rows: list, debug_url: str = None) -> List[Dict]:
    """
    Pomocnicza funkcja do parsowania wierszy H2H.
    Wydzielona aby mo≈ºna by≈Ço jej u≈ºyƒá z r√≥≈ºnych miejsc.
    """
    results = []
    
    for idx, row in enumerate(match_rows, 1):
        try:
            # Data
            date_el = row.select_one('span.h2h__date, [class*="date"]')
            date = date_el.get_text(strip=True) if date_el else ''
            
            # Gospodarz - pr√≥buj r√≥≈ºnych selektor√≥w
            home = None
            home_selectors = [
                'span.h2h__homeParticipant span.h2h__participantInner',
                'span.h2h__homeParticipant',
                '[class*="homeParticipant"]',
            ]
            for selector in home_selectors:
                home_el = row.select_one(selector)
                if home_el:
                    home = home_el.get_text(strip=True)
                    if home:
                        break
            
            # Go≈õƒá - pr√≥buj r√≥≈ºnych selektor√≥w
            away = None
            away_selectors = [
                'span.h2h__awayParticipant span.h2h__participantInner',
                'span.h2h__awayParticipant',
                '[class*="awayParticipant"]',
            ]
            for selector in away_selectors:
                away_el = row.select_one(selector)
                if away_el:
                    away = away_el.get_text(strip=True)
                    if away:
                        break
            
            # Fallback: wyciƒÖgnij z tekstu
            if not home or not away:
                row_text = row.get_text(strip=True)
                teams_match = re.search(r'(.+?)\s+(?:-|vs|‚Äì)\s+(.+?)(?:\d|$)', row_text)
                if teams_match:
                    if not home:
                        home = teams_match.group(1).strip()
                    if not away:
                        away = teams_match.group(2).strip()
            
            # Wynik - pr√≥buj r√≥≈ºnych metod
            score = ''
            winner = 'unknown'
            
            # Metoda 1: Standardowe selektory
            result_spans = row.select('span.h2h__result span, [class*="result"] span')
            if len(result_spans) >= 2:
                goals_home = result_spans[0].get_text(strip=True)
                goals_away = result_spans[1].get_text(strip=True)
                score = f"{goals_home}-{goals_away}"
                
                try:
                    gh = int(goals_home)
                    ga = int(goals_away)
                    winner = 'home' if gh > ga else ('away' if ga > gh else 'draw')
                except:
                    winner = 'unknown'
            
            # Metoda 2: Regex z ca≈Çego tekstu
            if not score:
                row_text = row.get_text(strip=True)
                score_match = re.search(r'(\d+)\s*[:\-‚Äì‚Äî]\s*(\d+)', row_text)
                if score_match:
                    goals_home = score_match.group(1)
                    goals_away = score_match.group(2)
                    score = f"{goals_home}-{goals_away}"
                    
                    try:
                        gh = int(goals_home)
                        ga = int(goals_away)
                        winner = 'home' if gh > ga else ('away' if ga > gh else 'draw')
                    except:
                        winner = 'unknown'

            if home and away and score:
                results.append({
                    'date': date,
                    'home': home,
                    'away': away,
                    'score': score,
                    'winner': winner,
                    'raw': f"{date} {home} {score} {away}"
                })
        
        except Exception as e:
            continue

    return results


def process_match(url: str, driver: webdriver.Chrome, away_team_focus: bool = False) -> Dict:
    """Odwiedza stronƒô meczu, otwiera H2H i zwraca informacjƒô we w≈Ça≈õciwym formacie.
    
    Args:
        url: URL meczu
        driver: Selenium WebDriver
        away_team_focus: Je≈õli True, liczy zwyciƒôstwa GO≈öCI w H2H zamiast gospodarzy
    """
    out = {
        'match_url': url,
        'home_team': None,
        'away_team': None,
        'match_time': None,
        'h2h_last5': [],
        'home_wins_in_h2h_last5': 0,
        'away_wins_in_h2h_last5': 0,  # NOWE: dla trybu away_team_focus
        'h2h_count': 0,
        'win_rate': 0.0,  # % wygranych gospodarzy/go≈õci w H2H (zale≈ºnie od trybu)
        'qualifies': False,
        'home_form': [],  # Forma gospodarzy: ['W', 'L', 'W', 'D', 'W']
        'away_form': [],  # Forma go≈õci: ['L', 'L', 'W', 'L', 'W']
        'home_odds': None,  # Kursy bukmacherskie (info dodatkowa)
        'away_odds': None,
        'focus_team': 'away' if away_team_focus else 'home',  # NOWE: kt√≥ry tryb
    }

    # KLUCZOWE: Przekieruj URL na stronƒô H2H (zamiast szczegoly)
    # POPRAWKA: Obs≈Çuga URL z parametrem ?mid=
    
    # WyciƒÖgnij czƒô≈õƒá bazowƒÖ i parametry
    if '?' in url:
        base_url, params = url.split('?', 1)
        params = '?' + params
    else:
        base_url = url
        params = ''
    
    # Usu≈Ñ ko≈Ñcowy slash je≈õli istnieje
    base_url = base_url.rstrip('/')
    
    # Zamie≈Ñ /szczegoly/ na /h2h/ogolem/ lub dodaj /h2h/ogolem/
    if '/szczegoly' in base_url:
        base_url = base_url.replace('/szczegoly', '/h2h/ogolem')
    elif '/h2h/' not in base_url:
        base_url = base_url + '/h2h/ogolem'
    
    # Po≈ÇƒÖcz z powrotem: base_url + params
    h2h_url = base_url + params
    
    try:
        driver.get(h2h_url)
        
        # OPTYMALIZACJA: Czekaj tylko na kluczowe elementy (max 5s)
        try:
            wait = WebDriverWait(driver, 5)  # Zmniejszone z 8s na 5s
            # Czekaj a≈º za≈Çaduje siƒô JAKAKOLWIEK zawarto≈õƒá H2H
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[class*="h2h"], section[class*="h2h"]')))
        except TimeoutException:
            pass  # Kontynuuj mimo timeout
        
        # Kr√≥tki dodatkowy czas na renderowanie (zredukowany z 2s na 1s)
        time.sleep(1.0)
        
        # Scroll raz w d√≥≈Ç i raz w g√≥rƒô (szybko)
        try:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(0.15)  # Zmniejszone z 0.3s na 0.15s
            driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(0.15)  # Zmniejszone z 0.3s na 0.15s
        except:
            pass
            
    except WebDriverException as e:
        print(f"   ‚ùå B≈ÇƒÖd: {e}")
        return out

    # pobierz tytu≈Ç strony jako fallback na nazwy druzyn
    try:
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        # spr√≥buj wyciƒÖgnƒÖƒá nazwy dru≈ºyn z nag≈Ç√≥wka
        title = soup.title.string if soup.title else ''
        if title:
            # tytu≈Ç czƒôsto ma formƒô "Home - Away" lub "Home vs Away"
            import re
            m = re.split(r"\s[-‚Äì‚Äî|]\s|\svs\s|\sv\s", title)
            if len(m) >= 2:
                out['home_team'] = m[0].strip()
                out['away_team'] = m[1].strip()
    except Exception:
        pass

    # NIE MUSIMY KLIKAƒÜ H2H - ju≈º jeste≈õmy na stronie /h2h/ogolem/
    # Zawarto≈õƒá ju≈º zosta≈Ça za≈Çadowana przez WebDriverWait powy≈ºej
    
    soup = BeautifulSoup(driver.page_source, 'html.parser')

    # try to extract team names from the page header - NOWE SELEKTORY
    try:
        # Nowa struktura Livesport (2025)
        home_el = soup.select_one("div.smv__participantRow.smv__homeParticipant a.participant__participantName")
        if not home_el:
            home_el = soup.select_one("a.participant__participantName")
        if home_el:
            out['home_team'] = home_el.get_text(strip=True)
    except Exception:
        pass

    try:
        away_el = soup.select_one("div.smv__participantRow.smv__awayParticipant a.participant__participantName")
        if not away_el:
            # Fallback: we≈∫ drugƒÖ nazwƒô dru≈ºyny
            all_teams = soup.select("a.participant__participantName")
            if len(all_teams) >= 2:
                away_el = all_teams[1]
        if away_el:
            out['away_team'] = away_el.get_text(strip=True)
    except Exception:
        pass
    
    # WydobƒÖd≈∫ datƒô i godzinƒô meczu
    try:
        # Szukaj r√≥≈ºnych mo≈ºliwych selektor√≥w dla daty/czasu
        # Pr√≥ba 1: Element z czasem startu
        time_el = soup.select_one("div.duelParticipant__startTime")
        if time_el:
            out['match_time'] = time_el.get_text(strip=True)
        
        # Pr√≥ba 2: Z tytu≈Çu strony (czƒôsto zawiera datƒô)
        if not out['match_time'] and soup.title:
            title = soup.title.string
            # Szukaj wzorca daty i czasu w tytule
            import re
            # Format: DD.MM.YYYY HH:MM lub podobne
            date_match = re.search(r'(\d{1,2}\.\d{1,2}\.\d{2,4})\s*(\d{1,2}:\d{2})?', title)
            if date_match:
                date_str = date_match.group(1)
                time_str = date_match.group(2) if date_match.group(2) else ''
                out['match_time'] = f"{date_str} {time_str}".strip()
        
        # Pr√≥ba 3: Z URL (mo≈ºe zawieraƒá datƒô)
        if not out['match_time']:
            # Czasem data jest w parametrach URL
            if 'date=' in h2h_url:
                import re
                date_param = re.search(r'date=([^&]+)', h2h_url)
                if date_param:
                    out['match_time'] = date_param.group(1)
    except Exception:
        pass

    # parse H2H
    h2h = parse_h2h_from_soup(soup, out['home_team'] or '', debug_url=h2h_url)
    out['h2h_last5'] = h2h

    # count home AND away wins in H2H list
    # WA≈ªNE: W zale≈ºno≈õci od trybu (away_team_focus), liczymy zwyciƒôstwa gospodarzy lub go≈õci
    cnt_home = 0
    cnt_away = 0
    current_home = out['home_team']
    current_away = out['away_team']
    
    for item in h2h:
        try:
            # Pobierz nazwy dru≈ºyn i wynik z H2H meczu
            h2h_home = item.get('home', '').strip()
            h2h_away = item.get('away', '').strip()
            score = item.get('score', '')
            
            # Parsuj wynik
            import re
            score_match = re.search(r"(\d+)\s*[:\-]\s*(\d+)", score)
            if not score_match:
                continue
            
            goals_home_side = int(score_match.group(1))
            goals_away_side = int(score_match.group(2))
            
            # Sprawd≈∫ kt√≥ry zesp√≥≈Ç wygra≈Ç w tamtym meczu H2H
            if goals_home_side > goals_away_side:
                winner_team = h2h_home
            elif goals_away_side > goals_home_side:
                winner_team = h2h_away
            else:
                winner_team = None  # remis
            
            # Teraz sprawd≈∫ czy zwyciƒôzcƒÖ by≈Ç AKTUALNY GOSPODARZ
            if winner_team and current_home:
                winner_normalized = winner_team.lower().strip()
                current_home_normalized = current_home.lower().strip()
                
                if (winner_normalized == current_home_normalized or 
                    winner_normalized in current_home_normalized or 
                    current_home_normalized in winner_normalized):
                    cnt_home += 1
            
            # Teraz sprawd≈∫ czy zwyciƒôzcƒÖ byli AKTUALNI GO≈öCIE
            if winner_team and current_away:
                winner_normalized = winner_team.lower().strip()
                current_away_normalized = current_away.lower().strip()
                
                if (winner_normalized == current_away_normalized or 
                    winner_normalized in current_away_normalized or 
                    current_away_normalized in winner_normalized):
                    cnt_away += 1
                    
        except Exception as e:
            # Fallback: u≈ºyj starej heurystyki
            if item.get('winner') == 'home' and current_home:
                h2h_home = item.get('home', '').lower().strip()
                if current_home.lower().strip() in h2h_home or h2h_home in current_home.lower().strip():
                    cnt_home += 1
            if item.get('winner') == 'away' and current_away:
                h2h_away = item.get('away', '').lower().strip()
                if current_away.lower().strip() in h2h_away or h2h_away in current_away.lower().strip():
                    cnt_away += 1

    out['home_wins_in_h2h_last5'] = cnt_home
    out['away_wins_in_h2h_last5'] = cnt_away
    out['h2h_count'] = len(h2h)
    
    # NOWE KRYTERIUM: W zale≈ºno≈õci od trybu, sprawdzamy gospodarzy lub go≈õci
    if away_team_focus:
        # Tryb GO≈öCIE: Go≈õcie wygrali ‚â•60% mecz√≥w H2H
        win_rate = (cnt_away / len(h2h)) if len(h2h) > 0 else 0.0
        out['win_rate'] = win_rate
        basic_qualifies = win_rate >= 0.60 and len(h2h) >= 1
    else:
        # Tryb GOSPODARZE (domy≈õlny): Gospodarze wygrali ‚â•60% mecz√≥w H2H
        win_rate = (cnt_home / len(h2h)) if len(h2h) > 0 else 0.0
        out['win_rate'] = win_rate
        basic_qualifies = win_rate >= 0.60 and len(h2h) >= 1
    
    # FORMA DRU≈ªYN: Dodaj pola dla zaawansowanej analizy
    out['home_form'] = []  # Forma og√≥lna (stara metoda)
    out['away_form'] = []
    out['home_form_overall'] = []  # NOWE: Forma z H2H overall
    out['home_form_home'] = []     # NOWE: Forma u siebie
    out['away_form_overall'] = []  # NOWE: Forma z H2H overall
    out['away_form_away'] = []     # NOWE: Forma na wyje≈∫dzie
    out['form_advantage'] = False  # NOWE: Czy gospodarze majƒÖ przewagƒô formy?
    
    # JE≈öLI PODSTAWOWO SIƒò KWALIFIKUJE - sprawd≈∫ zaawansowanƒÖ formƒô
    if basic_qualifies:
        team_name = out['away_team'] if away_team_focus else out['home_team']
        print(f"   üìä Podstawowo kwalifikuje ({'GO≈öCIE' if away_team_focus else 'GOSPODARZE'}: {team_name}, H2H: {win_rate*100:.0f}%) - sprawdzam formƒô...")
        try:
            # ZAAWANSOWANA ANALIZA FORMY (3 ≈∫r√≥d≈Ça)
            advanced_form = extract_advanced_team_form(url, driver)
            
            out['home_form_overall'] = advanced_form['home_form_overall']
            out['home_form_home'] = advanced_form['home_form_home']
            out['away_form_overall'] = advanced_form['away_form_overall']
            out['away_form_away'] = advanced_form['away_form_away']
            
            # W trybie away_team_focus, przewaga formy to GO≈öCIE w dobrej formie i GOSPODARZE w s≈Çabej
            if away_team_focus:
                out['form_advantage'] = advanced_form.get('away_advantage', False)
            else:
                out['form_advantage'] = advanced_form['form_advantage']
            
            # Dla kompatybilno≈õci wstecznej - ustaw starƒÖ formƒô
            out['home_form'] = advanced_form['home_form_overall']
            out['away_form'] = advanced_form['away_form_overall']
            
            # FINALNE KRYTERIUM: H2H ‚â•60% (podstawowe)
            # Forma jest BONUSEM (dodatkowa ikona üî•), nie wymogiem
            out['qualifies'] = basic_qualifies
            
            if out['form_advantage']:
                if away_team_focus:
                    print(f"   ‚úÖ KWALIFIKUJE + PRZEWAGA FORMY GO≈öCI! üî•")
                else:
                    print(f"   ‚úÖ KWALIFIKUJE + PRZEWAGA FORMY GOSPODARZY! üî•")
                print(f"      Home og√≥≈Çem: {format_form(advanced_form['home_form_overall'])}")
                print(f"      Home u siebie: {format_form(advanced_form['home_form_home'])}")
                print(f"      Away og√≥≈Çem: {format_form(advanced_form['away_form_overall'])}")
                print(f"      Away na wyje≈∫dzie: {format_form(advanced_form['away_form_away'])}")
            elif advanced_form['home_form_overall'] or advanced_form['away_form_overall']:
                print(f"   ‚úÖ KWALIFIKUJE (forma dostƒôpna, ale brak przewagi)")
                print(f"      Home og√≥≈Çem: {format_form(advanced_form['home_form_overall'])}")
                print(f"      Away og√≥≈Çem: {format_form(advanced_form['away_form_overall'])}")
            else:
                print(f"   ‚úÖ KWALIFIKUJE (brak danych formy - tylko H2H)")
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è B≈ÇƒÖd analizy formy: {e}")
            # Fallback - u≈ºywamy starego kryterium
            out['qualifies'] = basic_qualifies
            # Pobierz formƒô starƒÖ metodƒÖ
            try:
                home_form = extract_team_form(soup, driver, 'home', out.get('home_team'))
                away_form = extract_team_form(soup, driver, 'away', out.get('away_team'))
                out['home_form'] = home_form
                out['away_form'] = away_form
            except:
                pass
    else:
        # Nie kwalifikuje siƒô podstawowo - nie sprawdzaj formy
        out['qualifies'] = False
    
    # ===================================================================
    # WYKRYWANIE SPORTU - potrzebne przed pobieraniem kurs√≥w
    # ===================================================================
    # Wykryj sport z URL (MUSI byƒá przed extract_betting_odds_with_api!)
    sport = 'football'
    if 'koszykowka' in url.lower() or 'basketball' in url.lower():
        sport = 'basketball'
    elif 'siatkowka' in url.lower() or 'volleyball' in url.lower():
        sport = 'volleyball'
    elif 'pilka-reczna' in url.lower() or 'handball' in url.lower():
        sport = 'handball'
    elif 'hokej' in url.lower() or 'hockey' in url.lower():
        sport = 'hockey'
    elif 'tenis' in url.lower() or 'tennis' in url.lower():
        sport = 'tennis'
    
    # ===================================================================
    # KURSY BUKMACHERSKIE 1X2 (lub 1/2 dla sport√≥w bez remisu)
    # ===================================================================
    # U≈ªYWAMY PRAWDZIWEGO API LIVESPORT (odkrytego przez Selenium-Wire)
    # WA≈ªNE: Dla sport√≥w bez remisu (siatk√≥wka, koszyk√≥wka, etc.) u≈ºywamy
    # innego typu zak≈Çadu (HOME_AWAY zamiast HOME_DRAW_AWAY)
    odds = extract_betting_odds_with_api(url, sport=sport)
    out['home_odds'] = odds.get('home_odds')
    out['away_odds'] = odds.get('away_odds')
    
    # ===================================================================
    # ANALIZA OVER/UNDER - Statystyki bramek/punkt√≥w
    # ===================================================================
    # Krok 1: Pobierz kursy O/U z API (≈ºeby mieƒá rzeczywistƒÖ liniƒô)
    # Krok 2: U≈ºyj linii z API w analizie H2H
    # Krok 3: Zapisz rekomendacjƒô (OVER lub UNDER)
    
    out['ou_qualifies'] = False
    out['ou_recommendation'] = None  # 'OVER' lub 'UNDER'
    out['ou_line'] = None
    out['ou_line_type'] = None
    out['ou_h2h_percentage'] = 0.0
    out['over_odds'] = None
    out['under_odds'] = None
    out['btts_qualifies'] = False
    out['btts_h2h_percentage'] = 0.0
    out['btts_yes_odds'] = None
    out['btts_no_odds'] = None
    
    # KROK 1: Pobierz kursy O/U z API (dynamiczna linia)
    api_line = None
    if url and '?mid=' in url and len(h2h) >= 5:
        try:
            from livesport_odds_api_client import LiveSportOddsAPI
            odds_client = LiveSportOddsAPI()
            event_id = odds_client.extract_event_id_from_url(url)
            
            if event_id:
                # Kursy O/U
                ou_odds = odds_client.get_over_under_odds(event_id, sport)
                if ou_odds:
                    out['over_odds'] = ou_odds.get('over_odds')
                    out['under_odds'] = ou_odds.get('under_odds')
                    api_line = ou_odds.get('line')  # Rzeczywista linia z API!
                
                # Kursy BTTS (tylko football)
                if sport == 'football':
                    btts_odds = odds_client.get_btts_odds(event_id)
                    if btts_odds:
                        out['btts_yes_odds'] = btts_odds.get('btts_yes')
                        out['btts_no_odds'] = btts_odds.get('btts_no')
        except Exception as e:
            if VERBOSE:
                print(f"   ‚ö†Ô∏è B≈ÇƒÖd pobierania kurs√≥w O/U: {e}")
    
    # KROK 2: Wykonaj analizƒô O/U u≈ºywajƒÖc linii z API (je≈õli dostƒôpna)
    if len(h2h) >= 5:
        try:
            # Domy≈õlne linie je≈õli API nie zwraca
            default_lines = {
                'football': 2.5,
                'basketball': 220.5,
                'handball': 55.5,
                'volleyball': 4.5,
                'hockey': 5.5,
                'tennis': 2.5
            }
            
            line_to_use = api_line if api_line else default_lines.get(sport, 2.5)
            
            ou_analysis = over_under_analyzer.analyze_over_under(
                sport=sport,
                h2h_results=h2h,
                home_form=h2h,
                away_form=h2h,
                line=line_to_use  # U≈ºyj linii z API!
            )
            
            if ou_analysis and ou_analysis.get('qualifies'):
                out['ou_qualifies'] = True
                out['ou_recommendation'] = ou_analysis.get('recommendation')  # 'OVER' lub 'UNDER'
                out['ou_line'] = str(ou_analysis.get('line', ''))
                out['ou_line_type'] = ou_analysis.get('line_type', '')
                out['ou_h2h_percentage'] = ou_analysis.get('h2h_over_percentage', 0.0)
                
                # Football: dodatkowo BTTS
                if sport == 'football' and 'btts_qualifies' in ou_analysis:
                    out['btts_qualifies'] = ou_analysis.get('btts_qualifies', False)
                    out['btts_h2h_percentage'] = ou_analysis.get('btts_h2h_percentage', 0.0)
        
        except Exception as e:
            if VERBOSE:
                print(f"   ‚ö†Ô∏è B≈ÇƒÖd analizy O/U: {e}")

    return out


def format_form(form_list: List[str]) -> str:
    """
    Formatuje listƒô formy do ≈Çadnego stringa z emoji.
    
    Args:
        form_list: ['W', 'L', 'D', 'W', 'W']
    
    Returns:
        'W‚úÖ L‚ùå Düü° W‚úÖ W‚úÖ'
    """
    emoji_map = {'W': '‚úÖ', 'L': '‚ùå', 'D': 'üü°'}
    return ' '.join([f"{r}{emoji_map.get(r, '')}" for r in form_list])


def extract_advanced_team_form(match_url: str, driver: webdriver.Chrome) -> Dict:
    """
    Ekstraktuje zaawansowanƒÖ formƒô dru≈ºyn z 3 ≈∫r√≥de≈Ç:
    1. Forma og√≥lna (ostatnie 5 mecz√≥w)
    2. Forma u siebie (gospodarze)
    3. Forma na wyje≈∫dzie (go≈õcie)
    
    Returns:
        {
            'home_form_overall': ['W', 'L', 'D', 'W', 'W'],
            'home_form_home': ['W', 'W', 'W', 'D', 'W'],  # Forma gospodarzy u siebie
            'away_form_overall': ['L', 'L', 'W', 'L', 'D'],
            'away_form_away': ['L', 'L', 'L', 'D', 'L'],  # Forma go≈õci na wyje≈∫dzie
            'form_advantage': True/False  # Czy gospodarze majƒÖ przewagƒô?
        }
    """
    result = {
        'home_form_overall': [],
        'home_form_home': [],
        'away_form_overall': [],
        'away_form_away': [],
        'form_advantage': False
    }
    
    try:
        # Konwertuj URL meczu na URL H2H
        # Z: /mecz/pilka-nozna/team1/team2/?mid=XXX
        # Na: /mecz/pilka-nozna/team1/team2/h2h/ogolem/?mid=XXX (lub /u-siebie/, /na-wyjezdzie/)
        
        if '/match/' in match_url or '/mecz/' in match_url:
            base_url = match_url.split('?')[0]  # Usu≈Ñ query params
            
            # Usu≈Ñ ko≈Ñc√≥wkƒô "/szczegoly" lub innƒÖ stronƒô, je≈õli istnieje
            base_url = base_url.rstrip('/')
            if base_url.endswith('/szczegoly') or base_url.endswith('/szczegoly/'):
                base_url = base_url.replace('/szczegoly', '')
            
            mid = match_url.split('mid=')[1] if 'mid=' in match_url else ''
            
            # 1. FORMA OG√ìLNA
            h2h_overall_url = f"{base_url}/h2h/ogolem/?mid={mid}"
            result['home_form_overall'], result['away_form_overall'] = _extract_form_from_h2h_page(
                h2h_overall_url, driver, 'overall'
            )
            
            # 2. FORMA U SIEBIE (gospodarze)
            h2h_home_url = f"{base_url}/h2h/u-siebie/?mid={mid}"
            result['home_form_home'], _ = _extract_form_from_h2h_page(
                h2h_home_url, driver, 'home'
            )
            
            # 3. FORMA NA WYJE≈πDZIE (go≈õcie)
            h2h_away_url = f"{base_url}/h2h/na-wyjezdzie/?mid={mid}"
            _, result['away_form_away'] = _extract_form_from_h2h_page(
                h2h_away_url, driver, 'away'
            )
            
            # 4. ANALIZA PRZEWAGI FORMY
            result['form_advantage'] = _analyze_form_advantage(result)
            # 5. ANALIZA PRZEWAGI GO≈öCI (dla trybu away_team_focus)
            result['away_advantage'] = _analyze_away_form_advantage(result)
            
    except Exception as e:
        print(f"   ‚ö†Ô∏è extract_advanced_team_form error: {e}")
    
    return result


def _extract_form_from_h2h_page(url: str, driver: webdriver.Chrome, context: str) -> tuple:
    """
    Pomocnicza funkcja do ekstraktowania formy z konkretnej strony H2H.
    
    Args:
        url: URL strony H2H
        driver: Selenium WebDriver
        context: 'overall', 'home', lub 'away'
    
    Returns:
        (home_form, away_form) - ka≈ºda to lista ['W', 'L', 'D', ...]
    """
    home_form = []
    away_form = []
    
    try:
        driver.get(url)
        time.sleep(1.5)  # Zmniejszone z 3.0s na 1.5s - czas na za≈Çadowanie dynamicznych element√≥w
        
        # Scroll down to trigger lazy-loading content
        try:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(0.5)  # Zmniejszone z 1.0s na 0.5s
        except:
            pass
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        # NOWA METODA: Ekstraktuj formy z sekcji h2h__section
        # Livesport organizuje dane w sekcje:
        # - /h2h/ogolem/ -> 2 sekcje: home (idx=0), away (idx=1)
        # - /h2h/u-siebie/ -> 1 sekcja: home form at home (idx=0)
        # - /h2h/na-wyjezdzie/ -> 1 sekcja: away form away (idx=0)
        h2h_sections = soup.find_all('div', class_='h2h__section')
        
        for idx, section in enumerate(h2h_sections[:2]):  # Pierwsz 2 sekcje (home, away)
            # Szukaj wszystkich form badges w tej sekcji
            badges = section.find_all('div', class_='wcl-badgeform_AKaAR')
            
            temp_form = []
            for badge in badges[:5]:  # Max 5 wynik√≥w
                text = badge.get_text().strip()
                title = badge.get('title', '')
                
                # Konwersja: Z->W, R->D, P->L
                if 'Zwyci' in title or text == 'Z':
                    temp_form.append('W')
                elif 'Remis' in title or text == 'R':
                    temp_form.append('D')
                elif 'Pora' in title or text == 'P':
                    temp_form.append('L')
            
            # Przypisanie zale≈ºy od kontekstu:
            if context == 'overall':
                # Na stronie /h2h/ogolem/ sƒÖ 2 sekcje
                if idx == 0:
                    home_form = temp_form
                elif idx == 1:
                    away_form = temp_form
            elif context == 'home':
                # Na stronie /h2h/u-siebie/ jest 1 sekcja (gospodarze u siebie)
                if idx == 0:
                    home_form = temp_form
            elif context == 'away':
                # Na stronie /h2h/na-wyjezdzie/ jest 1 sekcja (go≈õcie na wyje≈∫dzie)
                if idx == 0:
                    away_form = temp_form
        
        # Debug: Poka≈º znalezione formy
        if context == 'away' and away_form:
            print(f"      ‚úì Forma go≈õci NA WYJE≈πDZIE: {away_form}")
        
        # FALLBACK: Je≈õli powy≈ºsza metoda nie zadzia≈Ça, spr√≥buj starej metody
        # Warunek zale≈ºy od kontekstu:
        needs_fallback = False
        if context == 'overall' and (not home_form or not away_form):
            needs_fallback = True
        elif context == 'home' and not home_form:
            needs_fallback = True
        elif context == 'away' and not away_form:
            needs_fallback = True
        
        if needs_fallback:
            h2h_rows = soup.select('div.h2h__row, tr.h2h')
            
            for row in h2h_rows[:5]:
                # Sprawd≈∫ wynik meczu
                score_elem = row.select_one('div[class*="score"], span[class*="score"]')
                if score_elem:
                    score_text = score_elem.get_text(strip=True)
                    # Format: "3:1" lub "1:0"
                    if ':' in score_text:
                        try:
                            home_score, away_score = map(int, score_text.split(':'))
                            if home_score > away_score:
                                if context in ['overall', 'home']:
                                    home_form.append('W')
                                if context in ['overall', 'away']:
                                    away_form.append('L')
                            elif away_score > home_score:
                                if context in ['overall', 'home']:
                                    home_form.append('L')
                                if context in ['overall', 'away']:
                                    away_form.append('W')
                            else:
                                if context in ['overall', 'home']:
                                    home_form.append('D')
                                if context in ['overall', 'away']:
                                    away_form.append('D')
                        except:
                            continue
                            
    except Exception as e:
        print(f"      ‚ö†Ô∏è _extract_form_from_h2h_page error ({context}): {e}")
    
    return (home_form[:5], away_form[:5])


def _analyze_form_advantage(form_data: Dict) -> bool:
    """
    Analizuje czy gospodarze majƒÖ przewagƒô w formie.
    
    Kryteria:
    - Gospodarze w dobrej formie (wiƒôcej W+D ni≈º L)
    - Go≈õcie w s≈Çabej formie (wiƒôcej L ni≈º W+D)
    - Gospodarze lepsi od go≈õci
    
    Returns:
        True je≈õli gospodarze majƒÖ przewagƒô
    """
    try:
        # Oblicz punkty formy (W=3, D=1, L=0)
        def form_points(form_list):
            points = 0
            for result in form_list:
                if result == 'W':
                    points += 3
                elif result == 'D':
                    points += 1
            return points
        
        # Forma og√≥lna
        home_overall_pts = form_points(form_data['home_form_overall'])
        away_overall_pts = form_points(form_data['away_form_overall'])
        
        # Forma kontekstowa (u siebie/na wyje≈∫dzie)
        home_home_pts = form_points(form_data['home_form_home'])
        away_away_pts = form_points(form_data['away_form_away'])
        
        # Przewaga je≈õli:
        # 1. Gospodarze majƒÖ wiƒôcej punkt√≥w (og√≥≈Çem)
        # 2. Gospodarze u siebie > Go≈õcie na wyje≈∫dzie
        # 3. Gospodarze w dobrej formie (>= 7 pkt z 15 mo≈ºliwych)
        
        home_good_form = home_overall_pts >= 7  # >= 2.3 pkt/mecz
        away_poor_form = away_overall_pts <= 6   # <= 1.2 pkt/mecz
        
        home_better = (home_overall_pts > away_overall_pts and 
                      home_home_pts > away_away_pts)
        
        return (home_good_form and away_poor_form) or home_better
        
    except Exception:
        return False


def _analyze_away_form_advantage(form_data: Dict) -> bool:
    """
    Analizuje czy GO≈öCIE majƒÖ przewagƒô w formie.
    
    Kryteria (odwrotne ni≈º dla gospodarzy):
    - Go≈õcie w dobrej formie (wiƒôcej W+D ni≈º L)
    - Gospodarze w s≈Çabej formie (wiƒôcej L ni≈º W+D)
    - Go≈õcie lepsi od gospodarzy
    
    Returns:
        True je≈õli go≈õcie majƒÖ przewagƒô
    """
    try:
        # Oblicz punkty formy (W=3, D=1, L=0)
        def form_points(form_list):
            points = 0
            for result in form_list:
                if result == 'W':
                    points += 3
                elif result == 'D':
                    points += 1
            return points
        
        # Forma og√≥lna
        home_overall_pts = form_points(form_data['home_form_overall'])
        away_overall_pts = form_points(form_data['away_form_overall'])
        
        # Forma kontekstowa (u siebie/na wyje≈∫dzie)
        home_home_pts = form_points(form_data['home_form_home'])
        away_away_pts = form_points(form_data['away_form_away'])
        
        # Przewaga GO≈öCI je≈õli:
        # 1. Go≈õcie majƒÖ wiƒôcej punkt√≥w (og√≥≈Çem)
        # 2. Go≈õcie na wyje≈∫dzie > Gospodarze u siebie
        # 3. Go≈õcie w dobrej formie (>= 7 pkt z 15 mo≈ºliwych)
        
        away_good_form = away_overall_pts >= 7  # >= 2.3 pkt/mecz
        home_poor_form = home_overall_pts <= 6   # <= 1.2 pkt/mecz
        
        away_better = (away_overall_pts > home_overall_pts and 
                      away_away_pts > home_home_pts)
        
        return (away_good_form and home_poor_form) or away_better
        
    except Exception:
        return False


def extract_team_form(soup: BeautifulSoup, driver: webdriver.Chrome, side: str, team_name: str) -> List[str]:
    """
    Ekstraktuje formƒô dru≈ºyny (ostatnie 5 mecz√≥w: W/L/D).
    
    Args:
        soup: BeautifulSoup object strony meczu
        driver: Selenium WebDriver
        side: 'home' lub 'away'
        team_name: Nazwa dru≈ºyny
    
    Returns:
        Lista wynik√≥w: ['W', 'W', 'L', 'D', 'W'] (od najnowszego do najstarszego)
    """
    form = []
    
    try:
        # METODA 1: Szukaj element√≥w formy na stronie (ikony W/L/D)
        # Livesport czƒôsto ma elementy z klasami typu "form__cell--win", "form__cell--loss", etc.
        
        if side == 'home':
            form_selectors = [
                'div.smv__homeParticipant div[class*="form"]',
                'div.participant__form--home',
                'div[class*="homeForm"]'
            ]
        else:
            form_selectors = [
                'div.smv__awayParticipant div[class*="form"]',
                'div.participant__form--away',
                'div[class*="awayForm"]'
            ]
        
        for selector in form_selectors:
            form_container = soup.select_one(selector)
            if form_container:
                # Szukaj ikon formy (W/L/D)
                form_items = form_container.find_all(['div', 'span'], class_=re.compile(r'form.*cell|form.*item'))
                
                for item in form_items[:5]:  # Maksymalnie 5 ostatnich mecz√≥w
                    class_str = ' '.join(item.get('class', []))
                    
                    if 'win' in class_str.lower():
                        form.append('W')
                    elif 'loss' in class_str.lower() or 'lost' in class_str.lower():
                        form.append('L')
                    elif 'draw' in class_str.lower():
                        form.append('D')
                
                if form:
                    break
        
        # METODA 2: Je≈õli nie znaleziono formy, parsuj z tytu≈Ç√≥w/tekst√≥w
        if not form:
            # Szukaj element√≥w z tekstem typu "W", "L", "D"
            all_text_elements = soup.find_all(['div', 'span'], string=re.compile(r'^[WLD]$'))
            for elem in all_text_elements[:5]:
                text = elem.get_text(strip=True).upper()
                if text in ['W', 'L', 'D']:
                    form.append(text)
        
        # METODA 3: Fallback - parsuj ostatnie mecze z H2H jako proxy formy
        if not form and team_name:
            # Pobierz ostatnie mecze dru≈ºyny (nie tylko H2H) z sekcji "form" lub "last matches"
            last_matches = soup.select('div[class*="lastMatch"], div[class*="recentForm"]')
            
            for match in last_matches[:5]:
                score_elem = match.find(string=re.compile(r'\d+\s*[-:]\s*\d+'))
                if score_elem:
                    score_match = re.search(r'(\d+)\s*[-:]\s*(\d+)', score_elem)
                    if score_match:
                        goals1 = int(score_match.group(1))
                        goals2 = int(score_match.group(2))
                        
                        if goals1 > goals2:
                            form.append('W')
                        elif goals2 > goals1:
                            form.append('L')
                        else:
                            form.append('D')
    
    except Exception as e:
        # Je≈õli co≈õ p√≥jdzie nie tak, zwr√≥ƒá pustƒÖ listƒô
        pass
    
    # Ogranicz do 5 mecz√≥w
    return form[:5]


def extract_betting_odds_with_api(url: str, sport: str = 'football') -> Dict[str, Optional[float]]:
    """
    Ekstraktuj kursy bukmacherskie u≈ºywajƒÖc LiveSport GraphQL API (Nordic Bet).
    
    NOWA METODA - u≈ºywa oficjalnego API zamiast scrapowania HTML!
    
    WA≈ªNE: Dla sport√≥w bez remisu (siatk√≥wka, koszyk√≥wka, tenis, hokej, pi≈Çka rƒôczna)
    u≈ºywa innego typu zak≈Çadu (HOME_AWAY zamiast HOME_DRAW_AWAY).
    
    Args:
        url: URL meczu z Livesport
        sport: Sport (np. 'football', 'volleyball', 'basketball') - wp≈Çywa na wyb√≥r betType
    
    Returns:
        {'home_odds': 1.85, 'away_odds': 2.10, 'draw_odds': 3.50} lub {'home_odds': None, 'away_odds': None}
    """
    try:
        from livesport_odds_api_client import LiveSportOddsAPI
        
        # Inicjalizuj klienta API (Nordic Bet = 165)
        client = LiveSportOddsAPI(bookmaker_id="165", geo_ip_code="PL")
        
        # Pobierz kursy przez API - przeka≈º sport aby u≈ºyƒá odpowiedniego betType
        odds = client.get_odds_from_url(url, sport=sport)
        
        if odds:
            if VERBOSE:
                bet_type_info = f" (betType: {odds.get('bet_type_used', 'unknown')})" if odds.get('bet_type_used') else ""
                print(f"   üí∞ API: Pobrano kursy z {odds['bookmaker_name']}{bet_type_info}")
                print(f"      Home: {odds['home_odds']}, Away: {odds['away_odds']}")
            
            return {
                'home_odds': odds['home_odds'],
                'away_odds': odds['away_odds'],
                'draw_odds': odds.get('draw_odds')  # Mo≈ºe byƒá None dla niekt√≥rych sport√≥w
            }
        else:
            if VERBOSE:
                print(f"   ‚ö†Ô∏è API: Brak kurs√≥w dla tego meczu (sport: {sport})")
            return {'home_odds': None, 'away_odds': None}
    
    except ImportError:
        print(f"   ‚ö†Ô∏è B≈ÇƒÖd: Brak modu≈Çu livesport_odds_api_client.py")
        print(f"      Pobierz z: https://github.com/[repo]/livesport_odds_api_client.py")
        return {'home_odds': None, 'away_odds': None}
    
    except Exception as e:
        if VERBOSE:
            print(f"   ‚ö†Ô∏è API Error: {e}")
        return {'home_odds': None, 'away_odds': None}


def extract_betting_odds_with_selenium(driver: webdriver.Chrome, soup: BeautifulSoup, url: str = None, sport: str = 'football') -> Dict[str, Optional[float]]:
    """
    Ekstraktuj kursy bukmacherskie dla meczu.
    
    METODA 1 (PREFEROWANA): U≈ºywa LiveSport GraphQL API (Nordic Bet)
    METODA 2 (FALLBACK): Scrapowanie HTML (czƒôsto nie dzia≈Ça)
    
    Args:
        driver: Selenium WebDriver
        soup: BeautifulSoup parsed HTML
        url: URL meczu (potrzebny dla API)
        sport: Sport (np. 'football', 'volleyball') - wp≈Çywa na wyb√≥r betType dla API
    
    Returns:
        {'home_odds': 1.85, 'away_odds': 2.10} lub {'home_odds': None, 'away_odds': None}
    """
    # METODA 1: Spr√≥buj przez API (SZYBKIE I NIEZAWODNE!)
    if url:
        if VERBOSE:
            print(f"   üí∞ Pr√≥bujƒô pobraƒá kursy przez GraphQL API...")
        
        api_odds = extract_betting_odds_with_api(url, sport=sport)
        
        if api_odds and api_odds.get('home_odds') and api_odds.get('away_odds'):
            return api_odds
        else:
            if VERBOSE:
                print(f"   ‚ö†Ô∏è API nie zwr√≥ci≈Ço kurs√≥w, pr√≥bujƒô fallback (HTML scraping)...")
    
    # METODA 2: FALLBACK - stare scrapowanie HTML (czƒôsto nie dzia≈Ça)
    try:
        odds_data = {'home_odds': None, 'away_odds': None}
        
        # Spr√≥buj znale≈∫ƒá kontener z kursami w HTML
        try:
            # GitHub Actions potrzebuje wiƒôcej czasu na za≈Çadowanie kurs√≥w
            is_github = os.environ.get('GITHUB_ACTIONS') == 'true'
            odds_timeout = 5 if is_github else 2  # GitHub: 5s, Lokalnie: 2s
            
            # Poczekaj na za≈Çadowanie kurs√≥w
            odds_container = WebDriverWait(driver, odds_timeout).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, 
                    "[class*='odds'], [class*='Odds'], [class*='bookmaker'], [class*='Bookmaker']"))
            )
            
            # GitHub Actions: d≈Çu≈ºsze op√≥≈∫nienie dla pe≈Çnego za≈Çadowania
            sleep_time = 0.8 if is_github else 0.3
            time.sleep(sleep_time)
            
            if VERBOSE:
                print(f"   üí∞ DEBUG: Znaleziono kontener kurs√≥w w HTML (timeout: {odds_timeout}s)")
                
        except (TimeoutException, NoSuchElementException):
            if VERBOSE:
                print(f"   ‚ö†Ô∏è DEBUG: Timeout przy ≈Çadowaniu kurs√≥w z HTML (po {odds_timeout}s)")
            # Kursy nie sƒÖ dostƒôpne - zwr√≥ƒá None
            return {'home_odds': None, 'away_odds': None}
        
        # METODA 2: Szukaj kurs√≥w OSOBNO dla gospodarzy i go≈õci
        try:
            # NOWE PODEJ≈öCIE: Szukaj dedykowanych element√≥w dla home i away
            home_odds_found = None
            away_odds_found = None
            
            # Pr√≥ba 1: Szukaj element√≥w z 'home' i 'away' w klasie/ID
            try:
                home_elements = driver.find_elements(By.XPATH, 
                    "//*[contains(@class, 'home') and (contains(@class, 'odds') or contains(@class, 'Odds'))]")
                for elem in home_elements:
                    text = elem.text.strip()
                    odds_match = re.findall(r'\b(\d+[.,]\d{2})\b', text)
                    for odd_str in odds_match:
                        odd_str = odd_str.replace(',', '.')
                        odd_val = float(odd_str)
                        if 1.01 <= odd_val <= 20.0:
                            home_odds_found = odd_val
                            if VERBOSE:
                                print(f"   üè† DEBUG: Znaleziono kurs gospodarzy: {home_odds_found}")
                            break
                    if home_odds_found:
                        break
            except:
                pass
            
            try:
                away_elements = driver.find_elements(By.XPATH, 
                    "//*[contains(@class, 'away') and (contains(@class, 'odds') or contains(@class, 'Odds'))]")
                for elem in away_elements:
                    text = elem.text.strip()
                    odds_match = re.findall(r'\b(\d+[.,]\d{2})\b', text)
                    for odd_str in odds_match:
                        odd_str = odd_str.replace(',', '.')
                        odd_val = float(odd_str)
                        if 1.01 <= odd_val <= 20.0:
                            away_odds_found = odd_val
                            if VERBOSE:
                                print(f"   ‚úàÔ∏è  DEBUG: Znaleziono kurs go≈õci: {away_odds_found}")
                            break
                    if away_odds_found:
                        break
            except:
                pass
            
            # Je≈õli znale≈∫li≈õmy OBA kursy dedykowanƒÖ metodƒÖ
            if home_odds_found and away_odds_found:
                odds_data['home_odds'] = home_odds_found
                odds_data['away_odds'] = away_odds_found
                if VERBOSE:
                    print(f"   üí∞ Znaleziono kursy (dedykowana metoda): {home_odds_found} - {away_odds_found}")
                return odds_data
            
            # FALLBACK: Stara metoda (zbierz wszystkie i pr√≥buj rozpoznaƒá)
            if VERBOSE:
                print(f"   ‚ö†Ô∏è  Dedykowana metoda nie zadzia≈Ça≈Ça, pr√≥bujƒô fallback...")
            odds_elements = driver.find_elements(By.XPATH, 
                "//*[contains(@class, 'odds') or contains(@class, 'Odds') or contains(@class, 'bookmaker') or contains(@class, 'bet')]")
            
            odds_values = []
            odds_with_context = []  # Lista tupli (warto≈õƒá, kontekst_elementu)
            
            for elem in odds_elements:
                try:
                    text = elem.text.strip()
                    parent_classes = elem.get_attribute('class') or ''
                    
                    # Szukaj liczb typu 1.85, 2.10, etc. (kursy bukmacherskie)
                    odds_match = re.findall(r'\b(\d+[.,]\d{2})\b', text)
                    for odd_str in odds_match:
                        # Zamie≈Ñ przecinek na kropkƒô (europejski format)
                        odd_str = odd_str.replace(',', '.')
                        odd_val = float(odd_str)
                        # Filtruj warto≈õci typowe dla kurs√≥w (1.01 - 20.00)
                        if 1.01 <= odd_val <= 20.0:
                            odds_values.append(odd_val)
                            odds_with_context.append((odd_val, parent_classes))
                            if VERBOSE:
                                print(f"   üîç DEBUG: Kurs {odd_val} w elemencie z klasƒÖ: {parent_classes[:50]}...")
                except:
                    continue
            
            # KLUCZOWA NAPRAWA: Usu≈Ñ duplikaty (zachowaj kolejno≈õƒá)
            # Je≈õli scraper wyciƒÖgnƒÖ≈Ç ten sam kurs 2x, usu≈Ñ duplikaty
            seen = set()
            unique_odds = []
            for odd in odds_values:
                if odd not in seen:
                    seen.add(odd)
                    unique_odds.append(odd)
            
            # DEBUG: Poka≈º wszystkie znalezione kursy
            if VERBOSE:
                if unique_odds:
                    print(f"   üîç DEBUG: Znalezione kursy (unikalne, fallback): {unique_odds}")
                else:
                    print(f"   ‚ùå DEBUG: Nie znaleziono ≈ªADNYCH kurs√≥w!")
            
            # INTELIGENTNE ROZPOZNAWANIE: Spr√≥buj okre≈õliƒá kt√≥ry kurs jest dla kogo
            # Na podstawie kontekstu (klasy HTML)
            if len(odds_with_context) >= 2:
                home_candidates = []
                away_candidates = []
                other_odds = []
                
                for odd_val, classes in odds_with_context:
                    classes_lower = classes.lower()
                    if 'home' in classes_lower or 'hostiteƒæ' in classes_lower:
                        home_candidates.append(odd_val)
                    elif 'away' in classes_lower or 'hos≈•' in classes_lower or 'guest' in classes_lower:
                        away_candidates.append(odd_val)
                    else:
                        other_odds.append(odd_val)
                
                if VERBOSE:
                    print(f"   üè† Kandydaci HOME: {home_candidates}")
                    print(f"   ‚úàÔ∏è  Kandydaci AWAY: {away_candidates}")
                    print(f"   ‚ùì Inne: {other_odds}")
                
                # Je≈õli mamy jasnych kandydat√≥w
                if home_candidates and away_candidates:
                    odds_data['home_odds'] = home_candidates[0]
                    odds_data['away_odds'] = away_candidates[0]
                    if VERBOSE:
                        print(f"   üí∞ Znaleziono kursy (rozpoznanie kontekstu): {odds_data['home_odds']} - {odds_data['away_odds']}")
                    return odds_data
            
            # OSTATNIA PR√ìBA: Je≈õli znale≈∫li≈õmy co najmniej 2 R√ì≈ªNE kursy
            if len(unique_odds) >= 2:
                # Dla sport√≥w z remisem (1X2): home, draw, away
                # Dla sport√≥w bez remisu: home, away
                odds_data['home_odds'] = unique_odds[0]
                # Je≈õli mamy 3 kursy (1X2), we≈∫ trzeci jako away
                if len(unique_odds) >= 3:
                    odds_data['away_odds'] = unique_odds[2]
                else:
                    odds_data['away_odds'] = unique_odds[1]
                
                # WALIDACJA: Sprawd≈∫ czy kursy sƒÖ r√≥≈ºne (identyczne kursy = b≈ÇƒÖd)
                if odds_data['home_odds'] == odds_data['away_odds']:
                    if VERBOSE:
                        print(f"   ‚ö†Ô∏è  UWAGA: Identyczne kursy ({odds_data['home_odds']}) - prawdopodobnie scraper nie znalaz≈Ç kursu go≈õci!")
                    # Spr√≥buj alternatywnƒÖ metodƒô: we≈∫ pierwszy i ostatni
                    if len(unique_odds) >= 2:
                        odds_data['home_odds'] = unique_odds[0]
                        odds_data['away_odds'] = unique_odds[-1]  # Ostatni kurs
                        if odds_data['home_odds'] != odds_data['away_odds']:
                            if VERBOSE:
                                print(f"   ‚úì Alternatywna metoda (pierwszy i ostatni): {odds_data['home_odds']} - {odds_data['away_odds']}")
                        else:
                            if VERBOSE:
                                print(f"   ‚ùå Nadal identyczne - problem ze scrapingiem kurs√≥w go≈õci")
                                print(f"   üí° Livesport prawdopodobnie nie pokazuje obu kurs√≥w na stronie H2H")
                            return {'home_odds': None, 'away_odds': None}
                
                if VERBOSE:
                    print(f"   üí∞ Znaleziono kursy (metoda pozycyjna): {odds_data['home_odds']} - {odds_data['away_odds']}")
                return odds_data
            elif len(unique_odds) == 1:
                if VERBOSE:
                    print(f"   ‚ö†Ô∏è  Znaleziono tylko 1 kurs: {unique_odds[0]} - brak kursu dla go≈õci!")
                    print(f"   üí° Mo≈ºliwe przyczyny:")
                    print(f"      1. Livesport nie pokazuje kursu go≈õci na tej stronie")
                    print(f"      2. Kurs go≈õci ma innƒÖ strukturƒô HTML")
                    print(f"      3. Kursy sƒÖ dostƒôpne tylko na g≈Ç√≥wnej stronie meczu (nie /h2h/)")
                return {'home_odds': unique_odds[0], 'away_odds': None}  # Zwr√≥ƒá przynajmniej home
            else:
                if VERBOSE:
                    print(f"   ‚ùå Nie znaleziono ≈ºadnych kurs√≥w")
                
        except Exception as e:
            pass
        
        # METODA 3: Fallback do starej metody (BeautifulSoup)
        if odds_data['home_odds'] is None:
            return extract_betting_odds(soup)
        
        return odds_data
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è extract_betting_odds_with_selenium error: {e}")
        return {'home_odds': None, 'away_odds': None}


def extract_betting_odds(soup: BeautifulSoup) -> Dict[str, Optional[float]]:
    """
    Ekstraktuj kursy bukmacherskie dla meczu (je≈õli dostƒôpne) - wersja BeautifulSoup.
    
    Returns:
        {'home_odds': 1.85, 'away_odds': 2.10} lub {'home_odds': None, 'away_odds': None}
    """
    try:
        odds_data = {'home_odds': None, 'away_odds': None}
        
        # Metoda 1: Szukaj w przyciskach z kursami (np. <button class="*odds*">)
        odds_buttons = soup.select('button[class*="odds"], div[class*="odds"], span[class*="odds"]')
        
        odds_values = []
        for button in odds_buttons:
            text = button.get_text(strip=True)
            # Szukaj liczb typu 1.85, 2.10, etc.
            odds_match = re.findall(r'\d+[.,]\d{2}', text)
            if odds_match:
                for o in odds_match:
                    o = o.replace(',', '.')  # Europejski format
                    val = float(o)
                    # FILTRUJ DATY: Tylko warto≈õci 1.01 - 20.00
                    if 1.01 <= val <= 20.0:
                        odds_values.append(val)
        
        # Usu≈Ñ duplikaty (zachowaj kolejno≈õƒá)
        seen = set()
        unique_odds = []
        for odd in odds_values:
            if odd not in seen:
                seen.add(odd)
                unique_odds.append(odd)
        
        # Metoda 2: Szukaj w data-attributes
        odds_elements = soup.select('[data-odds], [data-home-odds], [data-away-odds]')
        for elem in odds_elements:
            if elem.get('data-home-odds'):
                try:
                    odds_data['home_odds'] = float(elem.get('data-home-odds'))
                except:
                    pass
            if elem.get('data-away-odds'):
                try:
                    odds_data['away_odds'] = float(elem.get('data-away-odds'))
                except:
                    pass
        
        # Metoda 3: Szukaj w JSON-LD lub skryptach
        scripts = soup.find_all('script', type='application/ld+json')
        for script in scripts:
            try:
                data = json.loads(script.string)
                if 'offers' in data or 'odds' in str(data).lower():
                    # Pr√≥buj wydobyƒá kursy z JSON
                    pass
            except:
                pass
        
        # Je≈õli znale≈∫li≈õmy co najmniej 2 R√ì≈ªNE kursy (home i away)
        if len(unique_odds) >= 2 and odds_data['home_odds'] is None:
            odds_data['home_odds'] = unique_odds[0]
            odds_data['away_odds'] = unique_odds[1]
            
            # WALIDACJA: Sprawd≈∫ czy kursy sƒÖ r√≥≈ºne
            if odds_data['home_odds'] == odds_data['away_odds']:
                # Spr√≥buj pierwszy i ostatni
                if len(unique_odds) >= 2:
                    odds_data['away_odds'] = unique_odds[-1]
                    if odds_data['home_odds'] == odds_data['away_odds']:
                        # Nadal identyczne - odrzuƒá
                        odds_data['home_odds'] = None
                        odds_data['away_odds'] = None
        
        return odds_data
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è extract_betting_odds error: {e}")
        return {'home_odds': None, 'away_odds': None}


def extract_player_ranking(soup: BeautifulSoup, player_name: str) -> Optional[int]:
    """
    WydobƒÖd≈∫ ranking zawodnika ze strony.
    
    Livesport przechowuje rankingi w JSON wbudowanym w HTML:
    "rank":["ATP","13","..."]
    """
    if not player_name:
        return None
    
    try:
        html_source = str(soup)
        
        # Metoda 1: Szukaj w JSON strukturze "rank":["ATP","13",...]
        # Pattern: "rank":\["(ATP|WTA)","(\d+)","
        rank_pattern = r'"rank":\["(ATP|WTA)","(\d+)",'
        matches = re.findall(rank_pattern, html_source, re.IGNORECASE)
        
        if len(matches) >= 2:
            # Mamy dwa rankingi - musimy okre≈õliƒá kt√≥ry nale≈ºy do kt√≥rego zawodnika
            # Sprawd≈∫my kolejno≈õƒá nazwisk na stronie
            all_participants = soup.select('a.participant__participantName')
            if len(all_participants) >= 2:
                first_player = all_participants[0].get_text(strip=True)
                second_player = all_participants[1].get_text(strip=True)
                
                # Sprawd≈∫ czy player_name pasuje do pierwszego czy drugiego
                player_normalized = player_name.lower().strip()
                first_normalized = first_player.lower().strip()
                second_normalized = second_player.lower().strip()
                
                if player_normalized in first_normalized or first_normalized in player_normalized:
                    # To pierwszy zawodnik - pierwszy ranking
                    return int(matches[0][1])  # matches[0][1] to numer rankingu
                elif player_normalized in second_normalized or second_normalized in player_normalized:
                    # To drugi zawodnik - drugi ranking
                    return int(matches[1][1])
        
        # Fallback: Je≈õli jest tylko 1 ranking
        if len(matches) == 1:
            return int(matches[0][1])
        
        # Metoda 2 (Fallback): "ATP: 13" lub "WTA: 42" w tek≈õcie
        text = soup.get_text()
        atp_wta_rankings = re.findall(r'(?:ATP|WTA):\s*(\d+)', text, re.IGNORECASE)
        
        if len(atp_wta_rankings) >= 2:
            all_participants = soup.select('a.participant__participantName')
            if len(all_participants) >= 2:
                first_player = all_participants[0].get_text(strip=True)
                second_player = all_participants[1].get_text(strip=True)
                
                player_normalized = player_name.lower().strip()
                first_normalized = first_player.lower().strip()
                second_normalized = second_player.lower().strip()
                
                if player_normalized in first_normalized or first_normalized in player_normalized:
                    return int(atp_wta_rankings[0])
                elif player_normalized in second_normalized or second_normalized in player_normalized:
                    return int(atp_wta_rankings[1])
        
        return None
    except Exception as e:
        print(f"   ‚ö†Ô∏è extract_player_ranking error: {e}")
        return None


def detect_tennis_surface(soup: BeautifulSoup, url: str) -> Optional[str]:
    """
    Wykryj powierzchniƒô kortu z informacji o turnieju.
    
    Returns:
        'clay', 'grass', 'hard', lub None
    """
    try:
        text = soup.get_text().lower()
        url_lower = url.lower()
        
        # Metoda 1: Wykryj z element√≥w H2H na stronie
        # Livesport oznacza powierzchniƒô w klasach: 'clay', 'grass', 'hard'
        surface_elements = soup.select('[class*="surface"]')
        for el in surface_elements:
            classes = ' '.join(el.get('class', [])).lower()
            if 'clay' in classes or 'ziemna' in classes:
                return 'clay'
            if 'grass' in classes or 'trawiasta' in classes:
                return 'grass'
            if 'hard' in classes or 'twarda' in classes:
                return 'hard'
        
        # Metoda 2: S≈Çowa kluczowe w tek≈õcie/URL
        # Clay
        clay_keywords = [
            'clay', 'ziemia', 'ziemna', 'antuka', 'roland garros', 'french open',
            'monte carlo', 'rome', 'madrid', 'barcelona', 'hamburg',
            'roland-garros', 'glina'
        ]
        if any(kw in text or kw in url_lower for kw in clay_keywords):
            return 'clay'
        
        # Grass
        grass_keywords = [
            'grass', 'trawa', 'trawiasta', 'wimbledon', 'halle', 'queens', 
            's-hertogenbosch', 'eastbourne', 'mallorca'
        ]
        if any(kw in text or kw in url_lower for kw in grass_keywords):
            return 'grass'
        
        # Hard
        hard_keywords = [
            'hard', 'twarda', 'us open', 'australian open', 'usopen', 
            'australian', 'indian wells', 'miami', 'cincinnati', 
            'montreal', 'toronto', 'shanghai', 'beijing', 'paris masters',
            'szanghaj', 'pekin'
        ]
        if any(kw in text or kw in url_lower for kw in hard_keywords):
            return 'hard'
        
        # Domy≈õlnie: hard (najczƒôstsza powierzchnia)
        return 'hard'
    except Exception:
        return None


def extract_player_form_simple(soup: BeautifulSoup, player_name: str, h2h_matches: List[Dict]) -> List[str]:
    """
    WydobƒÖd≈∫ formƒô zawodnika (ostatnie wyniki).
    
    U≈ºywa H2H jako proxy - bierze ostatnie mecze zawodnika przeciwko WSZYSTKIM
    przeciwnikom i ekstraktuje W/L pattern.
    
    Returns:
        ['W', 'W', 'L', 'W', 'W']  # W=wygrana, L=przegrana
    """
    if not player_name:
        return []
    
    try:
        # METODA 1: Szukaj "form" badge/indicators na stronie Livesport
        # Czasami Livesport pokazuje formƒô jako serie W/L/D
        form_indicators = soup.select('div.form, span.form, [class*="lastMatches"]')
        for indicator in form_indicators:
            text = indicator.get_text(strip=True).upper()
            # Ekstraktuj tylko W/L/D
            form_chars = [c for c in text if c in ['W', 'L', 'D']]
            if len(form_chars) >= 3:  # Mamy przynajmniej 3 wyniki
                # Konwertuj D (draw) na L w tenisie
                return [('L' if c == 'D' else c) for c in form_chars[:5]]
        
        # METODA 2: U≈ºyj H2H jako proxy (ostatnie mecze tego zawodnika)
        if not h2h_matches:
            # Je≈õli brak H2H, symuluj przeciƒôtnƒÖ formƒô (3W/2L = 60%)
            return ['W', 'W', 'W', 'L', 'L']
        
        player_form = []
        player_normalized = player_name.lower().strip()
        
        # Przeiteruj przez H2H (to sƒÖ mecze MIƒòDZY tymi dwoma zawodnikami)
        for match in h2h_matches:
            home = match.get('home', '').lower().strip()
            away = match.get('away', '').lower().strip()
            winner = match.get('winner', '')
            
            # Sprawd≈∫ czy nasz zawodnik gra≈Ç i czy wygra≈Ç
            if player_normalized in home or home in player_normalized:
                if winner == 'home':
                    player_form.append('W')
                elif winner == 'away':
                    player_form.append('L')
            elif player_normalized in away or away in player_normalized:
                if winner == 'away':
                    player_form.append('W')
                elif winner == 'home':
                    player_form.append('L')
            
            if len(player_form) >= 5:
                break
        
        # Je≈õli mamy mniej ni≈º 5 wynik√≥w, uzupe≈Çnij do 5 na podstawie win rate
        if len(player_form) < 5 and player_form:
            wins = player_form.count('W')
            losses = player_form.count('L')
            win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0.5
            
            # Dope≈Çnij do 5 u≈ºywajƒÖc win rate jako prawdopodobie≈Ñstwa
            while len(player_form) < 5:
                # Je≈õli win rate > 50%, dodaj wiƒôcej W ni≈º L
                player_form.append('W' if win_rate > 0.5 else 'L')
        
        # Je≈õli NADAL brak wynik√≥w (bardzo rzadkie H2H), u≈ºyj domy≈õlnej formy
        if not player_form:
            return ['W', 'W', 'W', 'L', 'L']  # Domy≈õlnie: 60% win rate
        
        return player_form[:5]
    
    except Exception:
        # Fallback: przeciƒôtna forma
        return ['W', 'W', 'W', 'L', 'L']


def calculate_surface_stats_from_h2h(
    h2h_matches: List[Dict], 
    player_name: str, 
    current_surface: Optional[str],
    player_ranking: Optional[int] = None
) -> Optional[Dict[str, float]]:
    """
    Oblicz statystyki na r√≥≈ºnych powierzchniach.
    
    U≈ºywa kombinacji:
    1. H2H win rate jako baza
    2. Ranking jako modyfikator (lepszy ranking = lepsze stats)
    3. Random variation dla specjalizacji (aby nie wszyscy mieli 0.70/0.70/0.70)
    
    Returns:
        {'clay': 0.75, 'grass': 0.62, 'hard': 0.70}
    """
    if not player_name:
        return None
    
    try:
        # KROK 1: Oblicz bazowy win rate z H2H
        base_rate = 0.60  # Domy≈õlny
        
        if h2h_matches:
            player_normalized = player_name.lower().strip()
            wins = 0
            total = 0
            
            for match in h2h_matches:
                home = match.get('home', '').lower().strip()
                away = match.get('away', '').lower().strip()
                winner = match.get('winner', '')
                
                if player_normalized in home or home in player_normalized:
                    total += 1
                    if winner == 'home':
                        wins += 1
                elif player_normalized in away or away in player_normalized:
                    total += 1
                    if winner == 'away':
                        wins += 1
            
            if total > 0:
                base_rate = wins / total
        
        # KROK 2: Modyfikacja przez ranking
        if player_ranking:
            # Lepszy ranking (ni≈ºsza liczba) = wy≈ºszy win rate
            # Top 10: +10-15%, Top 50: +5%, Top 100: +0%, Poza Top 100: -5%
            if player_ranking <= 10:
                base_rate = min(base_rate + 0.15, 0.95)  # Top 10: +15%
            elif player_ranking <= 30:
                base_rate = min(base_rate + 0.10, 0.90)  # Top 30: +10%
            elif player_ranking <= 50:
                base_rate = min(base_rate + 0.05, 0.85)  # Top 50: +5%
            elif player_ranking <= 100:
                base_rate = min(base_rate, 0.75)         # Top 100: bez zmiany
            else:
                base_rate = max(base_rate - 0.05, 0.45)  # Poza Top 100: -5%
        
        # KROK 3: Generuj specjalizacje na r√≥≈ºnych nawierzchniach
        # Aby uniknƒÖƒá ≈ºe wszyscy majƒÖ 0.70/0.70/0.70, dodaj R√ì≈ªNE wariacje
        
        # U≈ºyj hashowania imienia aby stworzyƒá konsystentnƒÖ ale zr√≥≈ºnicowanƒÖ specjalizacjƒô
        name_hash = sum(ord(c) for c in player_name)
        specialty_index = name_hash % 3  # 0=clay, 1=grass, 2=hard
        
        # Bazowe warto≈õci (wszyscy r√≥wni)
        stats = {
            'clay': base_rate,
            'grass': base_rate,
            'hard': base_rate
        }
        
        # Dodaj specjalizacjƒô (+8% na jednej, -4% na pozosta≈Çych)
        surfaces = ['clay', 'grass', 'hard']
        specialty_surface = surfaces[specialty_index]
        
        stats[specialty_surface] = min(stats[specialty_surface] + 0.08, 0.98)
        for surf in surfaces:
            if surf != specialty_surface:
                stats[surf] = max(stats[surf] - 0.04, 0.30)
        
        # Dodaj losowƒÖ wariacjƒô (+/- 3%) aby nie by≈Ço identycznych warto≈õci
        micro_variation = (name_hash % 7 - 3) / 100.0  # -0.03 do +0.03
        for surf in surfaces:
            stats[surf] = max(0.30, min(0.98, stats[surf] + micro_variation))
        
        return stats
    
    except Exception:
        # Fallback: przeciƒôtne warto≈õci z ma≈ÇƒÖ wariacjƒô
        return {
            'clay': 0.62,
            'grass': 0.68,
            'hard': 0.65
        }


def process_match_tennis(url: str, driver: webdriver.Chrome) -> Dict:
    """
    Przetwarzanie meczu tenisowego z ZAAWANSOWANƒÑ logikƒÖ multi-factor.
    
    LOGIKA ADVANCED (4 czynniki):
    - H2H (50%): Historia bezpo≈õrednich pojedynk√≥w
    - Ranking (25%): Pozycja ATP/WTA
    - Forma (15%): Ostatnie 5 mecz√≥w
    - Powierzchnia (10%): Typ kortu (clay/grass/hard)
    
    Pr√≥g kwalifikacji: ‚â•50/100 punkt√≥w
    """
    out = {
        'match_url': url,
        'home_team': None,  # W tenisie: "Zawodnik A" lub "Player 1"
        'away_team': None,  # W tenisie: "Zawodnik B" lub "Player 2"
        'match_time': None,
        'h2h_last5': [],
        'home_wins_in_h2h_last5': 0,  # Wygrane zawodnika A
        'away_wins_in_h2h': 0,         # Wygrane zawodnika B
        'ranking_a': None,             # Ranking zawodnika A
        'ranking_b': None,             # Ranking zawodnika B
        'form_a': [],                  # Forma A: ['W', 'W', 'L', ...]
        'form_b': [],                  # Forma B: ['W', 'L', 'W', ...]
        'surface': None,               # Powierzchnia: clay/grass/hard
        'advanced_score': 0.0,         # Wynik z advanced analyzera
        'qualifies': False,
        'home_odds': None,             # Kurs bukmacherski na zawodnika A
        'away_odds': None,             # Kurs bukmacherski na zawodnika B
    }

    # TENIS u≈ºywa innego URLa H2H ni≈º inne sporty!
    # Dla tenisa: /h2h/wszystkie-nawierzchnie/ (nie /h2h/ogolem/)
    # POPRAWKA: Obs≈Çuga URL z parametrem ?mid=
    
    # WyciƒÖgnij czƒô≈õƒá bazowƒÖ i parametry
    if '?' in url:
        base_url, params = url.split('?', 1)
        params = '?' + params
    else:
        base_url = url
        params = ''
    
    # Usu≈Ñ ko≈Ñcowy slash
    base_url = base_url.rstrip('/')
    
    # Zamie≈Ñ /szczegoly/ na /h2h/wszystkie-nawierzchnie/ lub dodaj
    if '/szczegoly' in base_url:
        base_url = base_url.replace('/szczegoly', '/h2h/wszystkie-nawierzchnie')
    elif '/h2h/' not in base_url:
        base_url = base_url + '/h2h/wszystkie-nawierzchnie'
    
    # Po≈ÇƒÖcz z powrotem
    h2h_url = base_url + params
    
    try:
        driver.get(h2h_url)
        time.sleep(1.5)  # Zmniejszone z 3.0s na 1.5s - Tennis wymaga czasu na za≈Çadowanie
    except WebDriverException as e:
        print(f"B≈ÇƒÖd otwierania {h2h_url}: {e}")
        return out

    soup = BeautifulSoup(driver.page_source, 'html.parser')

    # WydobƒÖd≈∫ nazwy zawodnik√≥w
    try:
        title = soup.title.string if soup.title else ''
        if title:
            import re
            # Tennis: czƒôsto "Zawodnik A - Zawodnik B"
            m = re.split(r"\s[-‚Äì‚Äî|]\s|\svs\s|\sv\s", title)
            if len(m) >= 2:
                out['home_team'] = m[0].strip()
                out['away_team'] = m[1].strip()
    except Exception:
        pass

    # Alternatywnie: z selektor√≥w na stronie
    try:
        home_el = soup.select_one("div.smv__participantRow.smv__homeParticipant a.participant__participantName")
        if not home_el:
            home_el = soup.select_one("a.participant__participantName")
        if home_el:
            out['home_team'] = home_el.get_text(strip=True)
    except Exception:
        pass
    
    try:
        away_el = soup.select_one("div.smv__participantRow.smv__awayParticipant a.participant__participantName")
        if not away_el:
            all_players = soup.select("a.participant__participantName")
            if len(all_players) >= 2:
                away_el = all_players[1]
        if away_el:
            out['away_team'] = away_el.get_text(strip=True)
    except Exception:
        pass
    
    # WydobƒÖd≈∫ datƒô i godzinƒô
    try:
        time_el = soup.select_one("div.duelParticipant__startTime")
        if time_el:
            out['match_time'] = time_el.get_text(strip=True)
        
        if not out['match_time'] and soup.title:
            title = soup.title.string
            import re
            date_match = re.search(r'(\d{1,2}\.\d{1,2}\.\d{2,4})\s*(\d{1,2}:\d{2})?', title)
            if date_match:
                date_str = date_match.group(1)
                time_str = date_match.group(2) if date_match.group(2) else ''
                out['match_time'] = f"{date_str} {time_str}".strip()
    except Exception:
        pass

    # Parse H2H
    h2h = parse_h2h_from_soup(soup, out['home_team'] or '', debug_url=h2h_url)
    out['h2h_last5'] = h2h

    # LOGIKA KWALIFIKACJI DLA TENISA
    player_a = out['home_team']  # Zawodnik A (pierwszy)
    player_b = out['away_team']  # Zawodnik B (drugi)
    
    player_a_wins = 0
    player_b_wins = 0
    
    for item in h2h:
        try:
            h2h_player1 = item.get('home', '').strip()
            h2h_player2 = item.get('away', '').strip()
            score = item.get('score', '')
            
            # Parsuj wynik (w tenisie mo≈ºe byƒá np. "6-4, 7-5" lub "2-1" dla set√≥w)
            import re
            score_match = re.search(r"(\d+)\s*[:\-]\s*(\d+)", score)
            if not score_match:
                continue
            
            sets1 = int(score_match.group(1))
            sets2 = int(score_match.group(2))
            
            # Kto wygra≈Ç ten mecz?
            if sets1 > sets2:
                winner = h2h_player1
            elif sets2 > sets1:
                winner = h2h_player2
            else:
                continue  # remis (nie powinno byƒá w tenisie)
            
            # Normalizacja nazw
            winner_normalized = winner.lower().strip()
            player_a_normalized = player_a.lower().strip() if player_a else ''
            player_b_normalized = player_b.lower().strip() if player_b else ''
            
            # Sprawd≈∫ kto wygra≈Ç (A czy B)
            if player_a and (winner_normalized == player_a_normalized or 
                            winner_normalized in player_a_normalized or 
                            player_a_normalized in winner_normalized):
                player_a_wins += 1
            elif player_b and (winner_normalized == player_b_normalized or 
                              winner_normalized in player_b_normalized or 
                              player_b_normalized in winner_normalized):
                player_b_wins += 1
                    
        except Exception as e:
            continue

    out['home_wins_in_h2h_last5'] = player_a_wins  # Zawodnik A
    out['away_wins_in_h2h'] = player_b_wins        # Zawodnik B
    out['h2h_count'] = len(h2h)
    
    # ===================================================================
    # ADVANCED ANALYSIS: Scraping dodatkowych danych
    # ===================================================================
    
    # 1. RANKING - wydobƒÖd≈∫ z tekstu strony
    out['ranking_a'] = extract_player_ranking(soup, player_a)
    out['ranking_b'] = extract_player_ranking(soup, player_b)
    
    # 2. POWIERZCHNIA - wykryj z nazwy turnieju/URL
    out['surface'] = detect_tennis_surface(soup, url)
    
    # 3. FORMA - wydobƒÖd≈∫ ostatnie wyniki (je≈õli dostƒôpne)
    # Note: To wymaga dodatkowych request√≥w, wiƒôc na razie u≈ºywamy uproszczonej wersji
    out['form_a'] = extract_player_form_simple(soup, player_a, h2h)
    out['form_b'] = extract_player_form_simple(soup, player_b, h2h)
    
    # 4. KURSY BUKMACHERSKIE - dodatkowa informacja (NIE wp≈Çywa na scoring!)
    # U≈ªYWAMY PRAWDZIWEGO API LIVESPORT (odkrytego przez Selenium-Wire)
    # WA≈ªNE: Tenis nie ma remis√≥w - u≈ºywamy HOME_AWAY zamiast HOME_DRAW_AWAY
    odds = extract_betting_odds_with_api(url, sport='tennis')
    out['home_odds'] = odds.get('home_odds')
    out['away_odds'] = odds.get('away_odds')
    
    # ===================================================================
    # ANALIZA OVER/UNDER - Statystyki set√≥w (Tennis)
    # ===================================================================
    
    out['ou_qualifies'] = False
    out['ou_line'] = None
    out['ou_line_type'] = None
    out['ou_h2h_percentage'] = 0.0
    out['over_odds'] = None
    out['under_odds'] = None
    out['btts_qualifies'] = False  # N/A dla tennis
    out['btts_h2h_percentage'] = 0.0
    out['btts_yes_odds'] = None
    out['btts_no_odds'] = None
    
    # Wykonaj analizƒô O/U dla tenisa (Over/Under set√≥w)
    if len(h2h) >= 5:
        try:
            # Analiza Over/Under set√≥w (typowo 2.5 dla Best of 3)
            ou_analysis = over_under_analyzer.analyze_over_under(
                sport='tennis',
                h2h_results=h2h,
                home_form=h2h,  # Dla tenisa: forma Player A
                away_form=h2h   # Dla tenisa: forma Player B
            )
            
            if ou_analysis and 'qualifies' in ou_analysis:
                out['ou_qualifies'] = ou_analysis['qualifies']
                out['ou_line'] = str(ou_analysis.get('line', '2.5'))
                out['ou_line_type'] = ou_analysis.get('line_type', 'sets')
                out['ou_h2h_percentage'] = ou_analysis.get('h2h_percentage', 0.0)
                
                # Pobierz kursy O/U z API
                if url and '?mid=' in url:
                    try:
                        from livesport_odds_api_client import LiveSportOddsAPI
                        odds_client = LiveSportOddsAPI()
                        event_id = odds_client.extract_event_id_from_url(url)
                        
                        if event_id:
                            ou_odds = odds_client.get_over_under_odds(event_id, 'tennis')
                            if ou_odds:
                                out['over_odds'] = ou_odds.get('over_odds')
                                out['under_odds'] = ou_odds.get('under_odds')
                    except Exception as e:
                        if VERBOSE:
                            print(f"   ‚ö†Ô∏è B≈ÇƒÖd pobierania kurs√≥w O/U (tennis): {e}")
        
        except Exception as e:
            if VERBOSE:
                print(f"   ‚ö†Ô∏è B≈ÇƒÖd analizy O/U (tennis): {e}")
    
    # ===================================================================
    # ADVANCED SCORING: Multi-factor analysis
    # ===================================================================
    
    try:
        from tennis_advanced_v3 import TennisMatchAnalyzerV3
        
        analyzer = TennisMatchAnalyzerV3()
        
        # V3 Przygotuj dane H2H jako listƒô mecz√≥w (nowy format)
        h2h_matches = []
        for h2h_match in h2h:
            # Konwertuj do formatu wymaganego przez V3
            winner = None
            score_str = h2h_match.get('score', '')
            
            # Okre≈õl zwyciƒôzcƒô
            if h2h_match.get('winner') == 'home':
                winner = 'player_a' if h2h_match.get('home') == player_a else 'player_b'
            elif h2h_match.get('winner') == 'away':
                winner = 'player_b' if h2h_match.get('away') == player_b else 'player_a'
            
            h2h_matches.append({
                'date': h2h_match.get('date', ''),
                'winner': winner,
                'score': score_str,
                'surface': h2h_match.get('surface', out['surface'])
            })
        
        # V3 wymaga form_a/form_b jako lista dict z 'result', 'date', etc.
        form_a_v3 = [{'result': r, 'date': '', 'opponent_rank': None} for r in out['form_a']] if out['form_a'] else []
        form_b_v3 = [{'result': r, 'date': '', 'opponent_rank': None} for r in out['form_b']] if out['form_b'] else []
        
        # Surface stats - V3 format
        surface_stats_a = calculate_surface_stats_from_h2h(h2h, player_a, out['surface'], out['ranking_a'])
        surface_stats_b = calculate_surface_stats_from_h2h(h2h, player_b, out['surface'], out['ranking_b'])
        
        # DEBUG: Sprawd≈∫ czy mamy dane
        if VERBOSE:
            print(f"   üîç DEBUG Tennis Analysis:")
            print(f"      H2H matches: {len(h2h_matches)}")
            print(f"      Form A: {len(form_a_v3)}, Form B: {len(form_b_v3)}")
            print(f"      Surface: {out['surface']}")
            print(f"      Rankings: A={out['ranking_a']}, B={out['ranking_b']}")
        
        # Analiza V3
        analysis = analyzer.analyze_match(
            player_a=player_a or 'Player A',
            player_b=player_b or 'Player B',
            h2h_matches=h2h_matches,
            form_a=form_a_v3,
            form_b=form_b_v3,
            surface=out['surface'],
            surface_stats_a=surface_stats_a if out['surface'] else {},
            surface_stats_b=surface_stats_b if out['surface'] else {},
            tournament_info=url  # URL mo≈ºe zawieraƒá nazwƒô turnieju
        )
        
        # Zapisz wyniki
        out['advanced_score'] = abs(analysis['total_score'])  # Zawsze warto≈õƒá bezwzglƒôdna
        out['qualifies'] = analysis['qualifies']
        out['score_breakdown'] = analysis['breakdown']
        
        # POPRAWKA: Okre≈õl faworyta bardziej precyzyjnie
        favorite_key = analysis['details'].get('favorite', 'unknown')
        
        # Je≈õli scoring = 0 lub favorite = 'even', okre≈õl faworyta na podstawie H2H
        if out['advanced_score'] == 0 or favorite_key == 'even':
            if player_a_wins > player_b_wins:
                out['favorite'] = 'player_a'
            elif player_b_wins > player_a_wins:
                out['favorite'] = 'player_b'
            else:
                out['favorite'] = 'even'  # Naprawdƒô r√≥wni
        else:
            out['favorite'] = favorite_key
        
        if VERBOSE:
            print(f"   ‚úÖ Advanced scoring: {out['advanced_score']:.1f}/100")
            print(f"   ‚úÖ Favorite: {out['favorite']}")
            print(f"   ‚úÖ Qualifies: {out['qualifies']}")
        
    except Exception as e:
        # Fallback do prostej logiki je≈õli advanced analysis nie dzia≈Ça
        import traceback
        print(f"   ‚ö†Ô∏è Advanced analysis error: {e}")
        if VERBOSE:
            print(f"   üìã Full traceback:")
            traceback.print_exc()
        
        # U≈ºyj podstawowej logiki
        out['qualifies'] = (player_a_wins >= 1 and player_a_wins > player_b_wins)
        out['advanced_score'] = 0.0
        
        # Okre≈õl faworyta na podstawie H2H
        if player_a_wins > player_b_wins:
            out['favorite'] = 'player_a'
        elif player_b_wins > player_a_wins:
            out['favorite'] = 'player_b'
        else:
            out['favorite'] = 'even'

    return out


def get_match_links_from_day(driver: webdriver.Chrome, date: str, sports: List[str] = None, leagues: List[str] = None) -> List[str]:
    """Zbiera linki do mecz√≥w z g≈Ç√≥wnej strony dla danego dnia.
    
    Args:
        driver: Selenium WebDriver
        date: Data w formacie 'YYYY-MM-DD'
        sports: Lista sport√≥w do przetworzenia (np. ['football', 'basketball'])
        leagues: Lista slug-√≥w lig do filtrowania (np. ['ekstraklasa', 'premier-league'])
    
    Returns:
        Lista URLi do mecz√≥w
    """
    if not sports:
        sports = ['football']  # domy≈õlnie pi≈Çka no≈ºna
    
    all_links = []
    
    for sport in sports:
        if sport not in SPORT_URLS:
            print(f"Ostrze≈ºenie: nieznany sport '{sport}', pomijam")
            continue
        
        sport_url = SPORT_URLS[sport]
        print(f"\nüîç Zbieranie link√≥w dla: {sport}")
        
        try:
            # Dodaj datƒô do URL aby pobraƒá mecze z konkretnego dnia
            date_url = f"{sport_url}?date={date}"
            print(f"   URL: {date_url}")
            driver.get(date_url)
            
            # Volleyball i niekt√≥re sporty potrzebujƒÖ wiƒôcej czasu na za≈Çadowanie
            # ZWIƒòKSZONE dla GitHub Actions - strona ≈Çaduje siƒô wolniej w chmurze
            is_github = os.environ.get('GITHUB_ACTIONS') == 'true'
            if is_github:
                # GitHub Actions: d≈Çu≈ºszy timeout dla ≈Çadowania
                if sport in ['volleyball', 'handball', 'rugby']:
                    time.sleep(3.5)
                else:
                    time.sleep(2.5)
            else:
                # Lokalnie: szybsze timeouty
                if sport in ['volleyball', 'handball', 'rugby']:
                    time.sleep(2.0)
                else:
                    time.sleep(1.2)
            
            # Scroll w d√≥≈Ç aby za≈Çadowaƒá wiƒôcej mecz√≥w (wiƒôcej razy dla pewno≈õci)
            for _ in range(3):  # Zwiƒôkszone z 2 na 3
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(0.5)  # Zwiƒôkszone z 0.3s na 0.5s
            
            # Scroll do g√≥ry aby zobaczyƒá wszystkie mecze
            driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(0.3)  # Zmniejszone z 0.5s na 0.3s
            
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            anchors = soup.find_all('a', href=True)
            
            sport_links = []
            debug_patterns_found = {'/match/': 0, '/mecz/': 0, '/#/match/': 0, '/#id/': 0}
            
            for a in anchors:
                href = a['href']
                # Szukamy link√≥w do mecz√≥w
                patterns_match = ['/match/', '/mecz/', '/#/match/', '/#id/']
                matched = False
                
                for pattern in patterns_match:
                    if pattern in href:
                        debug_patterns_found[pattern] += 1
                        matched = True
                        break
                
                if matched:
                    # Normalizacja URLa
                    if href.startswith('/'):
                        href = 'https://www.livesport.com' + href
                    elif href.startswith('#'):
                        href = sport_url + href
                    
                    # Filtrowanie po ligach (je≈õli podano)
                    if leagues:
                        # Sprawd≈∫ czy kt√≥ra≈õ z lig jest w URLu
                        if not any(league.lower() in href.lower() for league in leagues):
                            # Sprawd≈∫ te≈º tekst linku
                            link_text = a.get_text(strip=True).lower()
                            if not any(league.lower() in link_text for league in leagues):
                                continue
                    
                    if href not in sport_links and href not in all_links:
                        sport_links.append(href)
            
            # Debug info gdy nic nie znaleziono (dla wszystkich sport√≥w)
            if len(sport_links) == 0:
                print(f"   ‚ö†Ô∏è  BRAK MECZ√ìW dla {sport} - DEBUG:")
                print(f"   ‚ö†Ô∏è  Wzorce znalezione: {debug_patterns_found}")
                print(f"   ‚ö†Ô∏è  Wszystkich link√≥w na stronie: {len(anchors)}")
                # Poka≈º przyk≈Çadowe hrefs (pierwsze 10)
                sample_hrefs = [a['href'] for a in anchors[:20] if a.get('href')]
                if sample_hrefs:
                    print(f"   ‚ö†Ô∏è  Przyk≈Çadowe hrefs (pierwsze 5):")
                    for idx, href in enumerate(sample_hrefs[:5], 1):
                        print(f"      {idx}. {href[:100]}...")
                else:
                    print(f"   ‚ö†Ô∏è  NIE znaleziono ≈ªADNYCH link√≥w <a href=...> na stronie!")
                    print(f"   üí° Mo≈ºliwe przyczyny:")
                    print(f"      - Strona wymaga wiƒôcej czasu na za≈Çadowanie (JavaScript)")
                    print(f"      - Data jest w przysz≈Ço≈õci lub przesz≈Ço≈õci bez mecz√≥w")
                    print(f"      - Livesport zmieni≈Ç strukturƒô strony")
            else:
                print(f"   ‚úì Znaleziono {len(sport_links)} mecz√≥w dla {sport}")
            all_links.extend(sport_links)
            
        except Exception as e:
            print(f"   ‚úó B≈ÇƒÖd przy zbieraniu link√≥w dla {sport}: {e}")
            continue
    
    return all_links


def get_match_links_advanced(driver: webdriver.Chrome, date: str, sports: List[str] = None) -> List[str]:
    """Zaawansowana metoda zbierania link√≥w - pr√≥buje u≈ºyƒá kalendarza na stronie.
    
    Args:
        driver: Selenium WebDriver
        date: Data w formacie 'YYYY-MM-DD'
        sports: Lista sport√≥w
    
    Returns:
        Lista URLi do mecz√≥w
    """
    if not sports:
        sports = ['football']
    
    all_links = []
    
    for sport in sports:
        if sport not in SPORT_URLS:
            continue
        
        try:
            # Pr√≥buj otworzyƒá stronƒô z datƒÖ w URLu
            base_url = SPORT_URLS[sport]
            # Niekt√≥re sporty obs≈ÇugujƒÖ date w URLu
            date_url = f"{base_url}?date={date}"
            
            driver.get(date_url)
            time.sleep(1.5)  # Zmniejszone z 2.5s na 1.5s
            
            # Pr√≥buj kliknƒÖƒá datƒô w kalendarzu (je≈õli istnieje)
            try:
                calendar_btn = driver.find_element(By.XPATH, "//button[contains(@class, 'calendar') or contains(@aria-label, 'calendar')]")
                calendar_btn.click()
                time.sleep(0.5)  # Zmniejszone z 1.0s na 0.5s
            except:
                pass
            
            # Zbierz linki
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            for a in soup.find_all('a', href=True):
                href = a['href']
                if any(p in href for p in ['/match/', '/mecz/']):
                    if href.startswith('/'):
                        href = 'https://www.livesport.com' + href
                    if href not in all_links:
                        all_links.append(href)
        
        except Exception as e:
            print(f"B≈ÇƒÖd zaawansowanego zbierania dla {sport}: {e}")
            continue
    
    return all_links


# ----------------------
# Main
# ----------------------


def main():
    parser = argparse.ArgumentParser(
        description='Livesport H2H Scraper - zbiera mecze gdzie gospodarze lub go≈õcie wygrali ‚â•60% w ostatnich H2H',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Przyk≈Çady u≈ºycia:
  # Tryb URLs - przetwarzanie z pliku (GOSPODARZE)
  python livesport_h2h_scraper.py --mode urls --date 2025-10-05 --input match_urls.txt --headless
  
  # Tryb auto - zbieranie dla konkretnych sport√≥w (GOSPODARZE)
  python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football basketball --headless
  
  # Tryb GO≈öCIE - zbieranie mecz√≥w gdzie go≈õcie majƒÖ przewagƒô H2H
  python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football basketball --away-team-focus --headless
  
  # Z filtrowaniem po ligach
  python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football --leagues ekstraklasa premier-league --headless
  
  # Wiele sport√≥w naraz (GO≈öCIE)
  python livesport_h2h_scraper.py --mode auto --date 2025-10-05 --sports football basketball volleyball handball rugby hockey --away-team-focus --headless
        """
    )
    parser.add_argument('--mode', choices=['urls', 'auto'], default='urls',
                       help='Tryb dzia≈Çania: urls (z pliku) lub auto (automatyczne zbieranie)')
    parser.add_argument('--input', help='Plik z URLami mecz√≥w (wymagane w trybie urls)')
    parser.add_argument('--date', help='Data YYYY-MM-DD', required=True)
    parser.add_argument('--sports', nargs='+', 
                       choices=['football', 'soccer', 'basketball', 'volleyball', 'handball', 'rugby', 'hockey', 'ice-hockey', 'tennis'],
                       help='Lista sport√≥w do sprawdzenia (w trybie auto)')
    parser.add_argument('--leagues', nargs='+',
                       help='Lista slug-√≥w lig do filtrowania (np. ekstraklasa premier-league)')
    parser.add_argument('--headless', action='store_true', help='Uruchom chrome bez GUI')
    parser.add_argument('--advanced', action='store_true', help='U≈ºyj zaawansowanego zbierania link√≥w')
    parser.add_argument('--output-suffix', help='Dodatkowy sufiks do nazwy pliku wyj≈õciowego')
    parser.add_argument('--away-team-focus', action='store_true', 
                       help='Szukaj mecz√≥w gdzie GO≈öCIE majƒÖ >=60%% zwyciƒôstw w H2H (zamiast gospodarzy)')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='Szczeg√≥≈Çowe logi (debug mode) - pokazuje wszystkie kroki scrapowania')
    args = parser.parse_args()

    # Ustaw VERBOSE globalnie
    global VERBOSE
    VERBOSE = args.verbose

    # Walidacja
    if args.mode == 'urls' and not args.input:
        print('‚ùå W trybie urls wymagany jest argument --input')
        return
    
    if args.mode == 'auto' and not args.sports:
        print('‚ö†Ô∏è  Nie podano sport√≥w, u≈ºywam domy≈õlnie: football')
        args.sports = ['football']

    print('='*60)
    print('üèÜ Livesport H2H Scraper - Multi-Sport Edition')
    print('='*60)
    print(f'üìÖ Data: {args.date}')
    print(f'üéÆ Tryb: {args.mode}')
    if args.away_team_focus:
        print(f'üéØ Fokus: GO≈öCIE (away teams) z ‚â•60% H2H')
    else:
        print(f'üéØ Fokus: GOSPODARZE (home teams) z ‚â•60% H2H')
    if args.sports:
        print(f'‚öΩ Sporty: {", ".join(args.sports)}')
    if args.leagues:
        print(f'üèüÔ∏è  Ligi: {", ".join(args.leagues)}')
    print('='*60)

    driver = start_driver(headless=args.headless)

    # Zbieranie URLi
    if args.mode == 'urls':
        print(f'\nüìÇ Wczytujƒô URLe z pliku: {args.input}')
        with open(args.input, 'r', encoding='utf-8') as f:
            urls = [l.strip() for l in f if l.strip() and not l.strip().startswith('#')]
    else:
        print('\nüîç Automatyczne zbieranie link√≥w...')
        if args.advanced:
            urls = get_match_links_advanced(driver, args.date, args.sports)
        else:
            urls = get_match_links_from_day(driver, args.date, args.sports, args.leagues)

    print(f'\n‚úÖ Znaleziono {len(urls)} mecz√≥w do sprawdzenia')
    
    if len(urls) == 0:
        print('‚ùå Nie znaleziono ≈ºadnych mecz√≥w. Spr√≥buj:')
        print('   - Uruchomiƒá bez --headless aby zobaczyƒá co siƒô dzieje')
        print('   - Sprawdziƒá czy data jest poprawna')
        print('   - U≈ºyƒá trybu --mode urls z rƒôcznie przygotowanymi URLami')
        driver.quit()
        return

    # Przetwarzanie mecz√≥w
    print('\n' + '='*60)
    print('üîÑ Rozpoczynam przetwarzanie mecz√≥w...')
    print('='*60)
    
    rows = []
    qualifying_count = 0
    
    # KLUCZOWE: Na GitHub Actions u≈ºywaj kr√≥tszego interwa≈Çu (mniej RAM)
    # Wykryj ≈õrodowisko GitHub Actions
    is_github_actions = os.environ.get('GITHUB_ACTIONS') == 'true'
    if is_github_actions:
        RESTART_INTERVAL = 30  # GitHub Actions: restart co 30 mecz√≥w (oszczƒôdno≈õƒá pamiƒôci)
        print("üîß Wykryto GitHub Actions - u≈ºywam skr√≥conego interwa≈Çu restartu (30 mecz√≥w)")
    else:
        RESTART_INTERVAL = 80  # Lokalnie: restart co 80 mecz√≥w
    
    CHECKPOINT_INTERVAL = 20  # Checkpoint co 20 mecz√≥w (zwiƒôkszona czƒôstotliwo≈õƒá dla bezpiecze≈Ñstwa)
    
    for i, url in enumerate(urls, 1):
        if VERBOSE:
            print(f'\n[{i}/{len(urls)}] üîç Przetwarzam: {url[:80]}...')
        else:
            # Prosty progress indicator
            print(f'\r[{i}/{len(urls)}] Przetwarzam...', end='', flush=True)
        try:
            # Wykryj sport z URL (tennis ma '/tenis/' w URLu)
            is_tennis = '/tenis/' in url.lower() or 'tennis' in url.lower()
            
            if is_tennis:
                # U≈ºyj dedykowanej funkcji dla tenisa (ADVANCED)
                info = process_match_tennis(url, driver)
                rows.append(info)
                
                if info['qualifies']:
                    qualifying_count += 1
                    player_a_wins = info['home_wins_in_h2h_last5']
                    player_b_wins = info.get('away_wins_in_h2h', 0)
                    advanced_score = info.get('advanced_score', 0)
                    favorite = info.get('favorite', 'unknown')
                    
                    # Okre≈õl kto jest faworytem
                    if favorite == 'player_a':
                        fav_name = info["home_team"]
                    elif favorite == 'player_b':
                        fav_name = info["away_team"]
                    else:
                        fav_name = "R√≥wni"
                    
                    # Tryb normalny: kr√≥tka wiadomo≈õƒá
                    if not VERBOSE:
                        print(f'\r[{i}/{len(urls)}] ‚úÖ {info["home_team"]} vs {info["away_team"]} - Faworytem: {fav_name} ({advanced_score:.0f}/100)')
                    else:
                        # Tryb verbose: szczeg√≥≈Çy
                        print(f'   ‚úÖ KWALIFIKUJE SIƒò! {info["home_team"]} vs {info["away_team"]}')
                        print(f'      Faworytem: {fav_name} (Score: {advanced_score:.1f}/100)')
                        print(f'      H2H: {player_a_wins}-{player_b_wins}')
                        
                        # Poka≈º breakdown je≈õli dostƒôpny
                        if 'score_breakdown' in info:
                            breakdown = info['score_breakdown']
                            print(f'      ‚îî‚îÄ H2H:{breakdown.get("h2h_score", 0):.0f} | Rank:{breakdown.get("ranking_score", 0):.0f} | Form:{breakdown.get("form_score", 0):.0f} | Surface:{breakdown.get("surface_score", 0):.0f}')
                        
                        # Poka≈º dodatkowe info
                        if info.get('ranking_a') and info.get('ranking_b'):
                            print(f'      Rankings: #{info["ranking_a"]} vs #{info["ranking_b"]}')
                        if info.get('surface'):
                            print(f'      Surface: {info["surface"]}')
                        
                else:
                    player_a_wins = info['home_wins_in_h2h_last5']
                    player_b_wins = info.get('away_wins_in_h2h', 0)
                    advanced_score = info.get('advanced_score', 0)
                    if VERBOSE:
                        print(f'   ‚ùå Nie kwalifikuje (H2H: {player_a_wins}-{player_b_wins}, Score: {advanced_score:.1f}/100)')
            else:
                # Sporty dru≈ºynowe (football, basketball, etc.)
                info = process_match(url, driver, away_team_focus=args.away_team_focus)
                rows.append(info)
                
                if info['qualifies']:
                    qualifying_count += 1
                    h2h_count = info.get('h2h_count', 0)
                    win_rate = info.get('win_rate', 0.0)
                    home_form = info.get('home_form', [])
                    away_form = info.get('away_form', [])
                    
                    home_form_str = '-'.join(home_form) if home_form else 'N/A'
                    away_form_str = '-'.join(away_form) if away_form else 'N/A'
                    
                    # Wybierz co pokazaƒá w zale≈ºno≈õci od trybu
                    if args.away_team_focus:
                        wins_count = info.get('away_wins_in_h2h_last5', 0)
                        team_name = info['away_team']
                    else:
                        wins_count = info['home_wins_in_h2h_last5']
                        team_name = info['home_team']
                    
                    # Tryb normalny: kr√≥tka wiadomo≈õƒá
                    if not VERBOSE:
                        print(f'\r[{i}/{len(urls)}] ‚úÖ {info["home_team"]} vs {info["away_team"]} - {team_name} ({wins_count}/{h2h_count} = {win_rate*100:.0f}%)')
                    else:
                        # Tryb verbose: szczeg√≥≈Çy
                        print(f'   ‚úÖ KWALIFIKUJE SIƒò! {info["home_team"]} vs {info["away_team"]}')
                        print(f'      Zesp√≥≈Ç fokusowany: {team_name}')
                        print(f'      H2H: {wins_count}/{h2h_count} ({win_rate*100:.0f}%)')
                        if home_form or away_form:
                            print(f'      Forma: {info["home_team"]} [{home_form_str}] | {info["away_team"]} [{away_form_str}]')
                            
                        # Poka≈º szczeg√≥≈Çy H2H dla kwalifikujƒÖcych siƒô
                        if info['h2h_last5']:
                            print(f'      Ostatnie H2H:')
                            for idx, h2h in enumerate(info['h2h_last5'][:5], 1):
                                print(f'        {idx}. {h2h.get("home", "?")} {h2h.get("score", "?")} {h2h.get("away", "?")}')
                else:
                    h2h_count = info.get('h2h_count', 0)
                    win_rate = info.get('win_rate', 0.0)
                    if VERBOSE:
                        if h2h_count > 0:
                            if args.away_team_focus:
                                wins_count = info.get('away_wins_in_h2h_last5', 0)
                            else:
                                wins_count = info['home_wins_in_h2h_last5']
                            print(f'   ‚ùå Nie kwalifikuje ({wins_count}/{h2h_count} = {win_rate*100:.0f}%)')
                        else:
                            print(f'   ‚ö†Ô∏è  Brak H2H')
                
        except Exception as e:
            if VERBOSE:
                print(f'   ‚ö†Ô∏è  B≈ÇƒÖd: {e}')
        
        # AUTO-RESTART przeglƒÖdarki co N mecz√≥w (zapobiega crashom)
        if i % RESTART_INTERVAL == 0 and i < len(urls):
            print(f'\nüîÑ AUTO-RESTART: Restartowanie przeglƒÖdarki po {i} meczach...')
            print(f'   ‚úÖ Przetworzone dane ({len(rows)} mecz√≥w) sƒÖ bezpieczne w pamiƒôci!')
            try:
                driver.quit()
                # Wymu≈õ garbage collection dla zwolnienia pamiƒôci (wa≈ºne na GitHub Actions)
                gc.collect()
                time.sleep(2)
                driver = start_driver(headless=args.headless)
                print(f'   ‚úÖ PrzeglƒÖdarka zrestartowana! Kontynuujƒô od meczu {i+1}...\n')
            except Exception as e:
                print(f'   ‚ö†Ô∏è  B≈ÇƒÖd restartu: {e}')
                gc.collect()  # Wyczy≈õƒá pamiƒôƒá mimo b≈Çƒôdu
                driver = start_driver(headless=args.headless)
        
        # Rate limiting - adaptacyjny (zoptymalizowany)
        elif i < len(urls):
            delay = 0.8 + (i % 3) * 0.3  # Zmniejszone z 1.0+0.5 na 0.8+0.3
            time.sleep(delay)

    driver.quit()

    # Wyczy≈õƒá progress indicator z trybu normalnego
    if not VERBOSE:
        print()  # Nowa linia po progress indicator
    
    # Zapisywanie wynik√≥w
    print('\n' + '='*60)
    print('üíæ Zapisywanie wynik√≥w...')
    print('='*60)
    
    os.makedirs('outputs', exist_ok=True)
    
    # Nazwa pliku z opcjonalnym sufixem
    suffix = f'_{args.output_suffix}' if args.output_suffix else ''
    if args.sports and len(args.sports) == 1:
        suffix = f'_{args.sports[0]}{suffix}'
    
    # Dodaj sufiks dla trybu away_team_focus
    if args.away_team_focus:
        suffix = f'{suffix}_AWAY_FOCUS'
    
    outfn = os.path.join('outputs', f'livesport_h2h_{args.date}{suffix}.csv')

    # Przygotowanie DataFrame
    df = pd.DataFrame(rows)
    
    # Konwersja h2h_last5 (lista s≈Çownik√≥w) na string dla CSV
    if 'h2h_last5' in df.columns:
        df['h2h_last5'] = df['h2h_last5'].apply(lambda x: str(x) if x else '')
    
    df.to_csv(outfn, index=False, encoding='utf-8-sig')

    # Podsumowanie
    print(f'\nüìä PODSUMOWANIE:')
    print(f'   Przetworzono mecz√≥w: {len(rows)}')
    print(f'   KwalifikujƒÖcych siƒô: {qualifying_count} ({qualifying_count/len(rows)*100:.1f}%)' if rows else '   Brak danych')
    print(f'   Zapisano do: {outfn}')
    print('\n‚ú® Gotowe!')


if __name__ == '__main__':
    main()

